{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7rGQLaD1mPGC"},"outputs":[],"source":["!pip install Vnstock --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTdW1DsfMof8"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from vnstock import Vnstock\n","from sklearn.linear_model import LinearRegression\n","from datetime import timedelta\n","\n","stock = Vnstock().stock()"]},{"cell_type":"markdown","metadata":{"id":"mD_6gT1y0aIY"},"source":["# Import Data"]},{"cell_type":"markdown","metadata":{"id":"KcxbVE1A30Ly"},"source":["T xem các chỉ số anh đó tính, công thức được tính dựa trên các chỉ số trên sàn chứng khoán, trong báo cáo kết quả hoạt động kinh doanh, và báo cáo lưu chuyển tiền tệ nhé"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14361,"status":"ok","timestamp":1745475864781,"user":{"displayName":"Quang To","userId":"03608325723169414899"},"user_tz":-420},"id":"2xlQmcfQzwFc","outputId":"cd424ca4-e639-4d5c-949f-7ec558b7f031"},"outputs":[{"output_type":"stream","name":"stderr","text":["2025-04-24 06:24:17 - vnstock.common.data.data_explorer - INFO - Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n","INFO:vnstock.common.data.data_explorer:Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n","2025-04-24 06:24:17 - vnstock.common.data.data_explorer - INFO - Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n","INFO:vnstock.common.data.data_explorer:Không phải là mã chứng khoán, thông tin công ty và tài chính không khả dụng.\n"]}],"source":["#Dữ liệu thị trường chứng khoán của FPT, CMG, VNINDEX, VN30 từ 2018 đến nay\n","start = '2017-08-24'\n","end = '2025-04-08'\n","VNINDEX = Vnstock().stock(symbol='VNINDEX')\n","VN30 = Vnstock().stock(symbol='VN30')\n","FPT = Vnstock().stock(symbol='FPT')\n","CMC = Vnstock().stock(symbol ='CMG')\n","\n","VNINDEX_stock = VNINDEX.quote.history(start=start, end=end, interval='1D')\n","VN30_stock = VN30.quote.history(start=start, end=end, interval='1D')\n","FPT_stock = FPT.quote.history(start=start, end=end, interval='1D')\n","CMC_stock = CMC.quote.history(start=start, end=end, interval='1D')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVTo1oI0zyz7"},"outputs":[],"source":["#Chỉ số trong BCTC từ đầu tới nay\n","FPT_ratio = FPT.finance.ratio(start=start, end=end)\n","CMC_ratio = CMC.finance.ratio(start=start, end=end)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MvShu89n3-Hg"},"outputs":[],"source":["#Tên của các DataFrame để dùng về sau\n","\n","      #Về thông số trên sàn chứng khoán: FPT_stock, CMG_stock, VNINDEX_stock, VN30_Stock\n","\n","      #Về các chỉ số trong BCTC: FPT_ratio, CMC_ratio"]},{"cell_type":"markdown","metadata":{"id":"GnqVDs4qVOzB"},"source":["# Data Preproccess"]},{"cell_type":"markdown","metadata":{"id":"FT6qJ1cEYoBt"},"source":["***Tên của các dataframe***\n","\n","      - Về thông số trên sàn chứng khoán: FPT_stock, CMG_stock, VNINDEX_stock, VN30_Stock\n","\n","      - Về bảng cân đối kế toán: FPT_balance_sheet\n","\n","      - Về báo cáo kết quả hoạt động kinh doanh: FPT_financial_report, CMG_financial_report\n","\n","      - Về báo cáo lưu chuyển tiền tệ: FPT_cash_flow, CMG_cash_flow"]},{"cell_type":"markdown","metadata":{"id":"0UaGV4Qm7CMc"},"source":["## **Phân tích Dữ liệu thị trường**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8bVfwqRKxu6"},"outputs":[],"source":["#Phân tích kỹ thuật\n","\n","def compute_technical_analysis(stock_data: pd.DataFrame, company_name: str):\n","    #3,7,21,63,100\n","    short_term3 = 3\n","    short_term7 = 7\n","    mid_term21 = 21\n","    mid_term63 = 63\n","    long_term100 = 100\n","\n","    # Tính MA\n","    MA_short_term3 = stock_data['close'].rolling(window=short_term3).mean()\n","    MA_short_term7 = stock_data['close'].rolling(window=short_term7).mean()\n","    MA_mid_term21 = stock_data['close'].rolling(window=mid_term21).mean()\n","    MA_mid_term63 = stock_data['close'].rolling(window=mid_term63).mean()\n","    MA_long_term100 = stock_data['close'].rolling(window=long_term100).mean()\n","\n","    # Tính RSI\n","    def compute_RSI(data, window=14):\n","        delta = data.diff()\n","        gain = delta.where(delta > 0, 0)\n","        loss = -delta.where(delta < 0, 0)\n","        avg_gain = gain.rolling(window=window, min_periods=window).mean()\n","        avg_loss = loss.rolling(window=window, min_periods=window).mean()\n","        rs = avg_gain / avg_loss\n","        rsi = 100 - (100 / (1 + rs))\n","        return rsi\n","\n","    RSI_short_term3 = compute_RSI(stock_data['close'], window=short_term3)\n","    RSI_mid_term7 = compute_RSI(stock_data['close'], window=short_term7)\n","    RSI_mid_term21 = compute_RSI(stock_data['close'], window=mid_term21)\n","    RSI_mid_term63 = compute_RSI(stock_data['close'], window=mid_term63)\n","    RSI_long_term100 = compute_RSI(stock_data['close'], window=long_term100)\n","\n","\n","    # Tính EMA\n","    def compute_EMA(data, window):\n","        return data.ewm(span=window, adjust=False).mean()\n","\n","    EMA_short_term3 = compute_EMA(stock_data['close'], short_term3)\n","    EMA_short_term7 = compute_EMA(stock_data['close'], short_term7)\n","    EMA_mid_term21 = compute_EMA(stock_data['close'], mid_term21)\n","    EMA_mid_term63 = compute_EMA(stock_data['close'], mid_term63)\n","    EMA_long_term100 = compute_EMA(stock_data['close'], long_term100)\n","\n","    # Tính Bollinger Bands\n","    def compute_bollinger_bands(data, window=20):\n","        rolling_mean = data.rolling(window=window).mean()\n","        rolling_std = data.rolling(window=window).std()\n","        upper_band = rolling_mean + 2 * rolling_std\n","        lower_band = rolling_mean - 2 * rolling_std\n","        return pd.DataFrame({\n","            'Middle Band': rolling_mean,\n","            'Upper Band': upper_band,\n","            'Lower Band': lower_band\n","        })\n","\n","    bollinger_bands = compute_bollinger_bands(stock_data['close'])\n","\n","    # Tính OBV\n","    def compute_OBV(data):\n","        obv = [0]\n","        for i in range(1, len(data)):\n","            if data['close'][i] > data['close'][i - 1]:\n","                obv.append(obv[-1] + data['volume'][i])\n","            elif data['close'][i] < data['close'][i - 1]:\n","                obv.append(obv[-1] - data['volume'][i])\n","            else:\n","                obv.append(obv[-1])\n","        return pd.Series(obv, index=data.index)\n","\n","    OBV = compute_OBV(stock_data)\n","\n","    # Tính ATR\n","    def compute_ATR(data, window=14):\n","        high = data['high']\n","        low = data['low']\n","        close = data['close']\n","        tr1 = high - low\n","        tr2 = abs(high - close.shift())\n","        tr3 = abs(low - close.shift())\n","        tr = pd.DataFrame({'tr1': tr1, 'tr2': tr2, 'tr3': tr3}).max(axis=1)\n","        return tr.rolling(window=window).mean()\n","\n","    ATR = compute_ATR(stock_data)\n","\n","    # Tính MACD\n","    def compute_MACD(data, short_window=12, long_window=26, signal_window=9):\n","        ema_short = data['close'].ewm(span=short_window, adjust=False).mean()\n","        ema_long = data['close'].ewm(span=long_window, adjust=False).mean()\n","        macd_line = ema_short - ema_long\n","        signal_line = macd_line.ewm(span=signal_window, adjust=False).mean()\n","        histogram = macd_line - signal_line\n","        return pd.DataFrame({\n","            'MACD': macd_line,\n","            'Signal Line': signal_line,\n","            'Histogram': histogram\n","        }, index=data.index)\n","\n","\n","    MACD = compute_MACD(stock_data)\n","\n","    #Tính EMA\n","    def compute_trix(stock_data, period):\n","        # EMA cấp 1\n","          ema1 = stock_data['close'].ewm(span=period, adjust=False).mean()\n","        # EMA cấp 2\n","          ema2 = ema1.ewm(span=period, adjust=False).mean()\n","        # EMA cấp 3\n","          ema3 = ema2.ewm(span=period, adjust=False).mean()\n","          return ema3\n","\n","    #Tính return day\n","    def compute_return(stock_data, period):\n","          return stock_data['close'].pct_change(period)\n","    return_day = compute_return(stock_data, 1)\n","    return_week = compute_return(stock_data, 7)\n","    return_month = compute_return(stock_data, 30)\n","\n","\n","\n","    # Calculate volatility\n","    def compute_volatility(stock_data, period):\n","        if period == 1:\n","            return stock_data['close'].pct_change()\n","        return stock_data['close'].pct_change().rolling(window = period).std()\n","    volatility_day = compute_volatility(stock_data, 1)\n","    volatility_week = compute_volatility(stock_data, 7)\n","    volatility_month = compute_volatility(stock_data, 30)\n","\n","    #Tính High-Close\n","    def compute_high_minus_close(stock_data):\n","        return stock_data['high'] - stock_data['close']\n","    high_minus_close = compute_high_minus_close(stock_data)\n","\n","    #Tính low-open\n","    def compute_low_minus_open(stock_data):\n","        return stock_data['low'] - stock_data['open']\n","    low_minus_open = compute_low_minus_open(stock_data)\n","\n","    #Tính cumulative return\n","    cumulative_return = (1 + stock_data['close'].pct_change()).cumprod()\n","\n","    #SMA\n","    def compute_SMA(stock_data, window):\n","        return stock_data['close'].rolling(window=window).mean()\n","    SMA_3 = compute_SMA(stock_data, 3)\n","    SMA_7 = compute_SMA(stock_data, 7)\n","    SMA_21 = compute_SMA(stock_data, 21)\n","    SMA_63 = compute_SMA(stock_data, 63)\n","    SMA_100 = compute_SMA(stock_data, 100)\n","\n","    #Tính return_day_std\n","    def compute_return_std(stock_data, period):\n","        if period == 1:\n","          return stock_data['close'].pct_change()\n","        return stock_data['close'].pct_change(period).rolling(window=period).std()\n","    return_day_std = compute_return_std(stock_data, 1)\n","    return_week_std = compute_return_std(stock_data, 7)\n","    return_month_std = compute_return_std(stock_data, 30)\n","\n","    #Tính liquidity\n","    def compute_liquidity(stock_data, period):\n","        volume_mean = stock_data['volume'].rolling(window=period).mean()\n","        close_mean = stock_data['close'].rolling(window=period).mean()\n","        return volume_mean * close_mean\n","\n","    liquidity_day = compute_liquidity(stock_data, 1)\n","    liquidity_week = compute_liquidity(stock_data, 7)\n","    liquidity_month = compute_liquidity(stock_data, 30)\n","\n","    #Tính MFI\n","    def calculate_mfi(high, low, close, volume, period=14):\n","        \"\"\"Calculates the Money Flow Index (MFI).\"\"\"\n","        typical_price = (high + low + close) / 3\n","        money_flow = typical_price * volume\n","\n","        # Positive and negative money flow\n","        positive_mf = []\n","        negative_mf = []\n","        for i in range(1, len(typical_price)):\n","            if typical_price[i] > typical_price[i-1]:\n","                positive_mf.append(money_flow[i])\n","                negative_mf.append(0)\n","            elif typical_price[i] < typical_price[i-1]:\n","                positive_mf.append(0)\n","                negative_mf.append(money_flow[i])\n","            else:\n","                positive_mf.append(0)\n","                negative_mf.append(0)\n","\n","        positive_mf = pd.Series(positive_mf)\n","        negative_mf = pd.Series(negative_mf)\n","\n","        # Money Flow Ratio\n","        positive_mf_sum = positive_mf.rolling(window=period).sum()\n","        negative_mf_sum = negative_mf.rolling(window=period).sum()\n","        money_flow_ratio = positive_mf_sum / negative_mf_sum\n","\n","        # Handle potential division by zero errors\n","        money_flow_ratio.fillna(1, inplace=True)  # Replace NaN with 1\n","\n","        # MFI\n","        mfi = 100 - (100 / (1 + money_flow_ratio))\n","        return mfi\n","\n","    stock_data['MFI_3'] = calculate_mfi(stock_data['high'], stock_data['low'], stock_data['close'], stock_data['volume'], period=3)\n","    stock_data['MFI_7'] = calculate_mfi(stock_data['high'], stock_data['low'], stock_data['close'], stock_data['volume'], period=7)\n","    stock_data['MFI_21'] = calculate_mfi(stock_data['high'], stock_data['low'], stock_data['close'], stock_data['volume'], period=21)\n","    stock_data['MFI_63'] = calculate_mfi(stock_data['high'], stock_data['low'], stock_data['close'], stock_data['volume'], period=63)\n","    stock_data['MFI_100'] = calculate_mfi(stock_data['high'], stock_data['low'], stock_data['close'], stock_data['volume'], period=100)\n","\n","    #Tính momentum\n","    def compute_momentum(stock_data, period):\n","        return stock_data['close'].pct_change(period)\n","\n","    stock_data['Momentum_3'] = compute_momentum(stock_data, 3)\n","    stock_data['Momentum_7'] = compute_momentum(stock_data, 7)\n","    stock_data['Momentum_21'] = compute_momentum(stock_data, 21)\n","    stock_data['Momentum_63'] = compute_momentum(stock_data, 63)\n","    stock_data['Momentum_100'] = compute_momentum(stock_data, 100)\n","\n","    #Tính rocr\n","    def compute_rocr(stock_data, period):\n","        return stock_data['close'].pct_change(period) * 100\n","\n","    stock_data['ROCR_3'] = compute_rocr(stock_data, 3)\n","    stock_data['ROCR_7'] = compute_rocr(stock_data, 7)\n","    stock_data['ROCR_21'] = compute_rocr(stock_data, 21)\n","    stock_data['ROCR_63'] = compute_rocr(stock_data, 63)\n","    stock_data['ROCR_100'] = compute_rocr(stock_data, 100)\n","\n","    #Tính CCI\n","    def compute_cci(data, period=20):\n","        typical_price = (data['high'] + data['low'] + data['close']) / 3\n","        sma = typical_price.rolling(window=period).mean()\n","        mad = (typical_price - sma).abs().rolling(window=period).mean()\n","        cci = (typical_price - sma) / (0.015 * mad)\n","        return cci\n","\n","    stock_data['CCI_3'] = compute_cci(stock_data, period=3)\n","    stock_data['CCI_7'] = compute_cci(stock_data, period=7)\n","    stock_data['CCI_21'] = compute_cci(stock_data, period=21)\n","    stock_data['CCI_63'] = compute_cci(stock_data, period=63)\n","    stock_data['CCI_100'] = compute_cci(stock_data, period=100)\n","\n","    #Tính William_r\n","    def compute_williams_r(data, period):\n","        high = data['high']\n","        low = data['low']\n","        close = data['close']\n","        highest_high = high.rolling(window=period).max()\n","        lowest_low = low.rolling(window=period).min()\n","        williams_r = ((highest_high - close) / (highest_high - lowest_low)) * 100\n","        return williams_r\n","\n","    stock_data['Williams_R_3'] = compute_williams_r(stock_data, 3)\n","    stock_data['Williams_R_7'] = compute_williams_r(stock_data, 7)\n","    stock_data['Williams_R_21'] = compute_williams_r(stock_data, 21)\n","    stock_data['Williams_R_63'] = compute_williams_r(stock_data, 63)\n","    stock_data['Williams_R_100'] = compute_williams_r(stock_data, 100)\n","\n","    def compute_adx(high, low, close, period=14):\n","        # Calculate True Range (TR)\n","        tr1 = high - low\n","        tr2 = np.abs(high - close.shift(1))\n","        tr3 = np.abs(low - close.shift(1))\n","        tr = pd.DataFrame({'tr1': tr1, 'tr2': tr2, 'tr3': tr3}).max(axis=1)\n","        plus_dm = pd.Series(np.where(((high - high.shift(1)) > (low.shift(1) - low)) & ((high - high.shift(1)) > 0), high - high.shift(1), 0), index=high.index) # Convert to pandas Series\n","        minus_dm = pd.Series(np.where(((low.shift(1) - low) > (high - high.shift(1))) & ((low.shift(1) - low) > 0), low.shift(1) - low, 0), index=low.index) # Convert to pandas Series\n","\n","        # Calculate Smoothed True Range (ATR)\n","        atr = tr.rolling(window=period).mean()\n","\n","        # Calculate Smoothed +DM and -DM\n","        plus_di = 100 * (plus_dm.rolling(window=period).sum() / atr)\n","        minus_di = 100 * (minus_dm.rolling(window=period).sum() / atr)\n","\n","        # Calculate Directional Index (DX)\n","        dx = 100 * np.abs((plus_di - minus_di) / (plus_di + minus_di))\n","\n","        # Handle division by zero\n","        dx = np.where(np.isnan(dx), 0, dx)\n","        dx = np.where(np.isinf(dx), 0, dx)\n","\n","        #Convert dx to pandas series\n","        dx = pd.Series(dx, index=high.index)\n","\n","        # Calculate Average Directional Index (ADX)\n","        adx = dx.rolling(window=period).mean()\n","        return pd.Series(adx, index=high.index)\n","\n","    stock_data['ADX_3'] = compute_adx(stock_data['high'], stock_data['low'], stock_data['close'], period=3)\n","    stock_data['ADX_7'] = compute_adx(stock_data['high'], stock_data['low'], stock_data['close'], period=7)\n","    stock_data['ADX_21'] = compute_adx(stock_data['high'], stock_data['low'], stock_data['close'], period=21)\n","    stock_data['ADX_63'] = compute_adx(stock_data['high'], stock_data['low'], stock_data['close'], period=63)\n","    stock_data['ADX_100'] = compute_adx(stock_data['high'], stock_data['low'], stock_data['close'], period=100)\n","\n","    #Tính trix\n","    def compute_trix(stock_data, period):\n","        ema1 = stock_data['close'].ewm(span=period, adjust = False).mean()\n","        ema2 = ema1.ewm(span=period, adjust = False).mean()\n","        ema3 = ema2.ewm(span=period, adjust = False).mean()\n","        trix = (ema3 - ema3.shift(period)) / (ema3.shift(period) * period)\n","        return trix\n","\n","    TRIX_short_term3 = compute_trix(stock_data, 3)\n","    TRIX_short_term7 = compute_trix(stock_data, 7)\n","    TRIX_mid_term21 = compute_trix(stock_data, 21)\n","    TRIX_mid_term63 = compute_trix(stock_data, 63)\n","    TRIX_long_term100 = compute_trix(stock_data, 100)\n","\n","    #Compute TSF\n","    def calculate_tsf(stock_data, period):\n","        if len(stock_data) < period:\n","            return None\n","\n","        close_prices = stock_data['close'].reset_index(drop=True)\n","        tsf_values = []\n","\n","        for i in range(period, len(close_prices)):\n","            x = np.arange(period)\n","            y = close_prices.iloc[i - period:i].values\n","\n","            coeffs = np.polyfit(x, y, 1)\n","            forecast = np.polyval(coeffs, period)\n","            tsf_values.append(forecast)\n","\n","        tsf_series = pd.Series([np.nan]*period + tsf_values, name=f'TSF_{period}')\n","        return tsf_series\n","\n","\n","    TSF_3 = calculate_tsf(stock_data, 3)\n","    TSF_7 = calculate_tsf(stock_data, 7)\n","    TSF_21 = calculate_tsf(stock_data, 21)\n","    TSF_63 = calculate_tsf(stock_data, 63)\n","    TSF_100 = calculate_tsf(stock_data, 100)\n","\n","\n","    # Gộp dữ liệu phân tích kỹ thuật\n","    technical_df = pd.DataFrame({\n","        f'Date': stock_data['time'],\n","        f'Open_{company_name}': stock_data['open'],\n","        f'High_{company_name}': stock_data['high'],\n","        f'Low_{company_name}': stock_data['low'],\n","        f'Close_{company_name}': stock_data['close'],\n","        f'Volume_{company_name}': stock_data['volume'],\n","        f'MA_short_term3_{company_name}': MA_short_term3,\n","        f'MA_short_term7_{company_name}': MA_short_term7,\n","        f'MA_mid_term21_{company_name}': MA_mid_term21,\n","        f'MA_mid_term63_{company_name}': MA_mid_term63,\n","        f'MA_long_term100_{company_name}': MA_long_term100,\n","        f'RSI_short_term3_{company_name}': RSI_short_term3,\n","        f'RSI_mid_term7_{company_name}': RSI_mid_term7,\n","        f'RSI_mid_term21_{company_name}': RSI_mid_term21,\n","        f'RSI_mid_term63_{company_name}': RSI_mid_term63,\n","        f'RSI_long_term100_{company_name}': RSI_long_term100,\n","        f'EMA_short_term3_{company_name}': EMA_short_term3,\n","        f'EMA_short_term7_{company_name}': EMA_short_term7,\n","        f'EMA_mid_term21_{company_name}': EMA_mid_term21,\n","        f'EMA_mid_term63_{company_name}': EMA_mid_term63,\n","        f'EMA_long_term100_{company_name}': EMA_long_term100,\n","        f'Upper_Band_{company_name}': bollinger_bands['Upper Band'],\n","        f'Lower_Band_{company_name}': bollinger_bands['Lower Band'],\n","        f'OBV_{company_name}': OBV,\n","        f'ATR_{company_name}': ATR,\n","        f'MACD_{company_name}': MACD['MACD'],\n","        f'Signal_Line_{company_name}': MACD['Signal Line'],\n","        f'Histogram_{company_name}': MACD['Histogram'],\n","        f'return_day_{company_name}': return_day,\n","        f'return_week_{company_name}': return_week,\n","        f'return_month_{company_name}': return_month,\n","        f'volatility_day_{company_name}': volatility_day,\n","        f'volatility_week_{company_name}': volatility_week,\n","        f'volatility_month_{company_name}': volatility_month,\n","        f'high_minus_close_{company_name}': high_minus_close,\n","        f'low_minus_open_{company_name}': low_minus_open,\n","        f'cumulative_return_{company_name}': cumulative_return,\n","        f'SMA_3_{company_name}': SMA_3,\n","        f'SMA_7_{company_name}': SMA_7,\n","        f'SMA_21_{company_name}': SMA_21,\n","        f'SMA_63_{company_name}': SMA_63,\n","        f'SMA_100_{company_name}': SMA_100,\n","        f'return_day_std_{company_name}': return_day_std,\n","        f'return_week_std_{company_name}': return_week_std,\n","        f'return_month_std_{company_name}': return_month_std,\n","        f'liquidity_day_{company_name}': liquidity_day,\n","        f'liquidity_week_{company_name}': liquidity_week,\n","        f'liquidity_month_{company_name}': liquidity_month,\n","        f'MFI_3_{company_name}': stock_data['MFI_3'],\n","        f'MFI_7_{company_name}': stock_data['MFI_7'],\n","        f'MFI_21_{company_name}': stock_data['MFI_21'],\n","        f'MFI_63_{company_name}': stock_data['MFI_63'],\n","        f'MFI_100_{company_name}': stock_data['MFI_100'],\n","        f'Momentum_3_{company_name}': stock_data['Momentum_3'],\n","        f'Momentum_7_{company_name}': stock_data['Momentum_7'],\n","        f'Momentum_21_{company_name}': stock_data['Momentum_21'],\n","        f'Momentum_63_{company_name}': stock_data['Momentum_63'],\n","        f'Momentum_100_{company_name}': stock_data['Momentum_100'],\n","        f'ROCR_3_{company_name}': stock_data['ROCR_3'],\n","        f'ROCR_7_{company_name}': stock_data['ROCR_7'],\n","        f'ROCR_21_{company_name}': stock_data['ROCR_21'],\n","        f'ROCR_63_{company_name}': stock_data['ROCR_63'],\n","        f'ROCR_100_{company_name}': stock_data['ROCR_100'],\n","        f'CCI_3_{company_name}': stock_data['CCI_3'],\n","        f'CCI_7_{company_name}': stock_data['CCI_7'],\n","        f'CCI_21_{company_name}': stock_data['CCI_21'],\n","        f'CCI_63_{company_name}': stock_data['CCI_63'],\n","        f'CCI_100_{company_name}': stock_data['CCI_100'],\n","        f'Williams_R_3_{company_name}': stock_data['Williams_R_3'],\n","        f'Williams_R_7_{company_name}': stock_data['Williams_R_7'],\n","        f'Williams_R_21_{company_name}': stock_data['Williams_R_21'],\n","        f'Williams_R_63_{company_name}': stock_data['Williams_R_63'],\n","        f'Williams_R_100_{company_name}': stock_data['Williams_R_100'],\n","        f'ADX_3_{company_name}': stock_data['ADX_3'],\n","        f'ADX_7_{company_name}': stock_data['ADX_7'],\n","        f'ADX_21_{company_name}': stock_data['ADX_21'],\n","        f'ADX_63_{company_name}': stock_data['ADX_63'],\n","        f'ADX_100_{company_name}': stock_data['ADX_100'],\n","        f'TRIX_short_term3_{company_name}': TRIX_short_term3,\n","        f'TRIX_short_term7_{company_name}': TRIX_short_term7,\n","        f'TRIX_mid_term21_{company_name}': TRIX_mid_term21,\n","        f'TRIX_mid_term63_{company_name}': TRIX_mid_term63,\n","        f'TRIX_long_term100_{company_name}': TRIX_long_term100,\n","        f'TSF_3_{company_name}': TSF_3,\n","        f'TSF_7_{company_name}': TSF_7,\n","        f'TSF_21_{company_name}': TSF_21,\n","        f'TSF_63_{company_name}': TSF_63,\n","        f'TSF_100_{company_name}': TSF_100\n","    })\n","    return technical_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wm_A_r65yzqC"},"outputs":[],"source":["FPT_analysis = compute_technical_analysis(FPT_stock, 'FPT')\n","CMC_analysis = compute_technical_analysis(CMC_stock, 'CMC')\n","VN30_analysis = compute_technical_analysis(VN30_stock, 'VN30')\n","VNINDEX_analysis = compute_technical_analysis(VNINDEX_stock, 'VNINDEX')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znqyQJKUy-su"},"outputs":[],"source":["def merge_data(df1, df2 = VN30_analysis, df3 = VNINDEX_analysis):\n","    merge_data = pd.merge(df2, df3, on=['Date'], how='right')\n","    merge_data = pd.merge(merge_data, df1, on=['Date'], how='right')\n","    return merge_data\n","FPT_merge_data = merge_data(FPT_analysis)\n","CMC_merge_data = merge_data(CMC_analysis)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OfPj3moVzOs6"},"outputs":[],"source":["def interpolate_data(data):\n","    columns_to_interpolate = data.columns[2:]\n","    data[columns_to_interpolate] = data[columns_to_interpolate].apply(pd.to_numeric, errors='coerce')\n","    for col in columns_to_interpolate:\n","      if data[col].isnull().any():\n","          data[col] = data[col].interpolate(method='linear', limit_direction='both')\n","    return data\n","FPT_market_after_analysis = interpolate_data(FPT_merge_data)\n","CMC_market_after_analysis = interpolate_data(CMC_merge_data)"]},{"cell_type":"markdown","metadata":{"id":"ohVr7gIc5JyC"},"source":["Output: FPT_market_after_analysis, CMC_market_after_analysis\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YHRSdyQUx65C"},"source":["## **Phân tích sức khỏe doanh nghiệp**"]},{"cell_type":"markdown","metadata":{"id":"ua0083DbB7sN"},"source":["**Ý nghĩa các cột trong Bảng cân đối kế toán**\n","\n","\n","---\n","\n","0. ticker: Tên mã cổ phiếu\n","1. yearReport: Năm báo cáo\n","2. lengthReport: Quý báo cáo\n","3. CURRENT ASSETS (Bn. VND): Tài sản ngắn hạn\n","4. Cash and cash equivalents (Bn. VND): Tiền và các khoản đương tiền\n","5. Short-term investments (Bn. VND): Các khoản đầu tư tài chính ngắn hạn\n","15. TOTAL ASSETS (Bn. VND): Tổng tài sản\n","16. OWNER'S EQUITY(Bn.VND): Vốn chủ sở hữu"]},{"cell_type":"markdown","metadata":{"id":"RQk5TgO27a-B"},"source":["**Ý nghĩa các cột trong Báo cáo kết quả hoạt động kinh doanh**\n","\n","\n","---\n","\n","\n","\n","0. ticker: tên Mã cổ phiếu\n","1. yearReport: Năm báo cáo\n","2. lengthReport: Quý báo cáo\n","3. Revenue YoY (%): Tăng trưởng doanh thu so với cùng kỳ\n","4. Revenue (Bn. VND): Doanh thu từ bán hàng\n","5. Attribute to parent company (Bn. VND): Lợi nhuận sau thuế của cổ đông công ty mẹ\n","6. Attribute to parent company YoY (%): Tăng trưởng doanh thu cho cổ đông công ty mẹ so với cùng kỳ\n","7. Financial Income: Doanh thu từ bán hàng\n","8. Interest Expenses: Chi phí lãi vay\n","9. Sales: Doanh thu bán hàng\n","10. Sales deductions: Các khoản giảm trừ\n","11. Net Sales: Doanh thu thuần\n","12. Cost of Sales: Giá vốn hàng bán\n","13. Gross Profit: Lợi nhuận gộp\n","14. Financial Expenses: Chi phí tài chính\n","15. Gain/(loss) from joint ventures: Lợi nhuận từ công ty liên doanh\n","16. Selling Expenses: Chi phí bán hàng\n","17. General & Admin Expenses: Chi phí quản lí doanh nghiệp\n","18. Operating Profit/Loss: Lợi nhuận thuần từ hoạt động kinh doanh\n","19. Other income: Thu nhập khác\n","20. Net income from associated companies: Lợi nhuận thuần từ công ty liên kết\n","21. Other Income/Expenses: Chi phí khác\n","22. Net other income/expenses: Lợi nhuận khác\n","23. Profit before tax: Tổng lợi nhuận kế toán trước thuế\n","24. Business income tax - current: Chi phí thuế TNDN hiện hành\n","25. Business income tax - deferred: Chi phí thuế TNDN hoãn lại\n","26. Net Profit For the Year: Lợi nhuận sau thuế thu nhập doanh nghiệp\n","27. Minority Interest: Lợi nhuận sau thuế của cổ đông không kiểm soát\n","28. Attributable to parent company: Lợi nhuận sau thuế của công ty mẹ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pt2zDLbkCUO"},"outputs":[],"source":["def data_prepare(ratio: pd.DataFrame):\n","    # Xóa các cột bậc 1\n","    ratio.columns = ratio.columns.droplevel(0)\n","\n","    # Đổi dữ liệu từ quý sang ngày\n","    quarter_end = {\n","        '1': '03-31',\n","        '2': '06-30',\n","        '3': '09-30',\n","        '4': '12-31'\n","    }\n","\n","    ratio['Date'] = ratio.apply(\n","        lambda row: pd.to_datetime(f\"{row['yearReport']}-{quarter_end.get(str(row['lengthReport']), '01-01')}\"),\n","        axis=1\n","    )\n","\n","    # Sắp xếp lại thứ tự cột\n","    cols = ['ticker', 'Date'] + [col for col in ratio.columns if col not in ['Date', 'ticker']]\n","    ratio = ratio[cols]\n","\n","    # Xóa các cột không cần\n","    ratio.drop(columns=['yearReport', 'lengthReport', 'ticker'], inplace=True)\n","\n","    # Sắp xếp theo thời gian\n","    ratio = ratio.sort_values(by='Date')\n","\n","    # Tạo đầy đủ các ngày từ đầu năm đầu tiên đến cuối năm cuối cùng\n","    full_dates = pd.DataFrame({\n","        'Date': pd.date_range(start=ratio['Date'].min(), end=end, freq='D')\n","    })\n","\n","    # Merge để có đầy đủ ngày\n","    ratio_full = pd.merge(full_dates, ratio, on='Date', how='left')\n","\n","    # Fill các giá trị thiếu bằng giá trị gần nhất trước đó\n","    ratio_full = ratio_full.fillna(method='ffill')\n","\n","    # Giữ lại các dòng từ năm bắt đầu trở đi\n","    ratio_full = ratio_full[ratio_full['Date'] >= '2017-08-23']\n","\n","    # Reset lại index\n","    ratio_full.reset_index(drop=True, inplace=True)\n","\n","    return ratio_full"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1745475883977,"user":{"displayName":"Quang To","userId":"03608325723169414899"},"user_tz":-420},"id":"jyjiR9b3z1zD","outputId":"885e3b94-038d-4f38-ad33-65d00fd73d39"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","\n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n"]}],"source":["FPT_ratio_after_analysis = data_prepare(FPT_ratio)\n","CMC_ratio_after_analysis = data_prepare(CMC_ratio)"]},{"cell_type":"markdown","metadata":{"id":"kT2xbC0y9AV3"},"source":["Dữ liệu sức khỏe doanh nghiệp: FPT_ratio_after_analysis\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PleK7DBT9N-l"},"source":["## Ghép hai file phân tích"]},{"cell_type":"markdown","metadata":{"id":"rrlnGHeB9q2y"},"source":["***Tên của hai file phân tích***\n","\n","- File phân tích dữ liệu thị trường: FPT_market_after_analysis, CMC_market_after_analysis\n","\n","- File phân tích sức khỏe doanh nghiệp: FPT_ratio_after_analysis, CMC_ratio_after_analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bLsOXTX9fJn"},"outputs":[],"source":["def merge_data(df1, df2):\n","    # Name of the market file\n","    # Name of the ratio file\n","    merge_data = pd.merge(df2, df1, on=['Date'], how='right')\n","    merge_data = merge_data.interpolate(method='linear', limit_direction='both')\n","    return merge_data\n","\n","FPT_after_analysis = merge_data(FPT_market_after_analysis, FPT_ratio_after_analysis)\n","CMC_after_analysis = merge_data(CMC_market_after_analysis, CMC_ratio_after_analysis)"]},{"cell_type":"markdown","metadata":{"id":"uAO62cQNAlE9"},"source":["File kết quả đưa vào PCA\n","\n","FPT_after_analysis\n","CMC_after_analysis\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SspuKNJiAzYZ"},"source":["##  Raw Filter\n","\n","- Các file sau khi đã được xử lý: FPT_after_analysis, CMC_after_analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dqeWONMBCiZ"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler, RobustScaler, PowerTransformer, StandardScaler, QuantileTransformer\n","from sklearn.pipeline import Pipeline\n","import matplotlib.pyplot as plt\n","import pandas as pd\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qZv-oILOKzau"},"outputs":[],"source":["import pandas as pd\n","from scipy.stats import pearsonr\n","\n","def filter_features(company_after_analysis, company_name: str, coefficient_corr_drop=0.1, coefficient_p_value_drop=0.05):\n","    # Bước 1: Chọn các cột dữ liệu không phải 'Date' và lấy biến mục tiêu\n","    columns = company_after_analysis.drop(columns=['Date']).columns\n","    Y = company_after_analysis[f'Close_{company_name}']\n","\n","    # Bước 2: Tính ma trận tương quan\n","    corr_matrix = company_after_analysis[columns].corr()\n","\n","    # Bước 3: Lọc các cột có tương quan thấp với biến mục tiêu\n","    col_to_drop = [\n","        col for col in corr_matrix.columns\n","        if col != f'Close_{company_name}' and abs(corr_matrix[f'Close_{company_name}'][col]) < coefficient_corr_drop\n","    ]\n","\n","    # Bước 4: Lọc các cột có p-value cao hơn threshold\n","    for col in columns:\n","        p_value = pearsonr(Y, company_after_analysis[col])[1]\n","        if not pd.isna(p_value) and p_value > coefficient_p_value_drop:\n","            col_to_drop.append(col)\n","\n","    # Bước 5: In ra thông tin các cột bị loại bỏ\n","    print(f\"Số cột cần loại bỏ: {len(col_to_drop)}\")\n","    print(\"Cột bị loại:\", col_to_drop)\n","\n","    # Bước 6: Trả về dữ liệu sau khi loại bỏ các cột không cần thiết\n","    return company_after_analysis.drop(columns=col_to_drop)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3773,"status":"ok","timestamp":1745475887826,"user":{"displayName":"Quang To","userId":"03608325723169414899"},"user_tz":-420},"id":"M3t7fIBtLNbm","outputId":"e8f5902b-a76e-417c-ca25-b36c159f1102"},"outputs":[{"output_type":"stream","name":"stdout","text":["Số cột cần loại bỏ: 212\n","Cột bị loại: ['(ST+LT borrowings)/Equity', 'Asset Turnover', 'Days Sales Outstanding', 'Cash Ratio', 'Financial Leverage', 'RSI_short_term3_VN30', 'RSI_mid_term7_VN30', 'RSI_mid_term21_VN30', 'RSI_mid_term63_VN30', 'RSI_long_term100_VN30', 'ATR_VN30', 'MACD_VN30', 'Signal_Line_VN30', 'Histogram_VN30', 'return_day_VN30', 'return_week_VN30', 'return_month_VN30', 'volatility_day_VN30', 'high_minus_close_VN30', 'low_minus_open_VN30', 'return_day_std_VN30', 'MFI_3_VN30', 'MFI_7_VN30', 'MFI_21_VN30', 'Momentum_3_VN30', 'Momentum_7_VN30', 'Momentum_21_VN30', 'Momentum_63_VN30', 'Momentum_100_VN30', 'ROCR_3_VN30', 'ROCR_7_VN30', 'ROCR_21_VN30', 'ROCR_63_VN30', 'ROCR_100_VN30', 'CCI_3_VN30', 'CCI_7_VN30', 'CCI_21_VN30', 'Williams_R_3_VN30', 'Williams_R_7_VN30', 'Williams_R_21_VN30', 'Williams_R_63_VN30', 'ADX_3_VN30', 'ADX_7_VN30', 'TRIX_short_term3_VN30', 'TRIX_short_term7_VN30', 'TRIX_mid_term21_VN30', 'TRIX_mid_term63_VN30', 'TRIX_long_term100_VN30', 'RSI_short_term3_VNINDEX', 'RSI_mid_term7_VNINDEX', 'RSI_mid_term21_VNINDEX', 'RSI_mid_term63_VNINDEX', 'ATR_VNINDEX', 'MACD_VNINDEX', 'Signal_Line_VNINDEX', 'Histogram_VNINDEX', 'return_day_VNINDEX', 'return_week_VNINDEX', 'return_month_VNINDEX', 'volatility_day_VNINDEX', 'high_minus_close_VNINDEX', 'low_minus_open_VNINDEX', 'return_day_std_VNINDEX', 'MFI_3_VNINDEX', 'MFI_7_VNINDEX', 'MFI_21_VNINDEX', 'MFI_63_VNINDEX', 'MFI_100_VNINDEX', 'Momentum_3_VNINDEX', 'Momentum_7_VNINDEX', 'Momentum_21_VNINDEX', 'Momentum_63_VNINDEX', 'ROCR_3_VNINDEX', 'ROCR_7_VNINDEX', 'ROCR_21_VNINDEX', 'ROCR_63_VNINDEX', 'CCI_3_VNINDEX', 'CCI_7_VNINDEX', 'CCI_21_VNINDEX', 'CCI_63_VNINDEX', 'Williams_R_3_VNINDEX', 'Williams_R_7_VNINDEX', 'Williams_R_21_VNINDEX', 'Williams_R_63_VNINDEX', 'Williams_R_100_VNINDEX', 'ADX_3_VNINDEX', 'ADX_7_VNINDEX', 'ADX_63_VNINDEX', 'ADX_100_VNINDEX', 'TRIX_short_term3_VNINDEX', 'TRIX_short_term7_VNINDEX', 'TRIX_mid_term21_VNINDEX', 'TRIX_mid_term63_VNINDEX', 'TRIX_long_term100_VNINDEX', 'RSI_short_term3_FPT', 'RSI_mid_term7_FPT', 'RSI_mid_term21_FPT', 'RSI_mid_term63_FPT', 'Histogram_FPT', 'return_day_FPT', 'return_week_FPT', 'return_month_FPT', 'volatility_day_FPT', 'volatility_week_FPT', 'volatility_month_FPT', 'return_day_std_FPT', 'return_week_std_FPT', 'return_month_std_FPT', 'MFI_3_FPT', 'MFI_7_FPT', 'MFI_63_FPT', 'MFI_100_FPT', 'Momentum_3_FPT', 'Momentum_7_FPT', 'Momentum_21_FPT', 'ROCR_3_FPT', 'ROCR_7_FPT', 'ROCR_21_FPT', 'CCI_3_FPT', 'CCI_7_FPT', 'CCI_21_FPT', 'Williams_R_3_FPT', 'Williams_R_7_FPT', 'Williams_R_21_FPT', 'Williams_R_63_FPT', 'ADX_3_FPT', 'ADX_7_FPT', 'ADX_21_FPT', 'TRIX_short_term3_FPT', 'TRIX_short_term7_FPT', 'Days Sales Outstanding', 'Cash Ratio', 'RSI_short_term3_VN30', 'RSI_mid_term7_VN30', 'RSI_mid_term21_VN30', 'MACD_VN30', 'Signal_Line_VN30', 'Histogram_VN30', 'return_day_VN30', 'return_week_VN30', 'return_month_VN30', 'volatility_day_VN30', 'high_minus_close_VN30', 'low_minus_open_VN30', 'return_day_std_VN30', 'Momentum_3_VN30', 'Momentum_7_VN30', 'Momentum_21_VN30', 'ROCR_3_VN30', 'ROCR_7_VN30', 'ROCR_21_VN30', 'CCI_3_VN30', 'CCI_7_VN30', 'CCI_21_VN30', 'Williams_R_3_VN30', 'Williams_R_21_VN30', 'ADX_3_VN30', 'ADX_7_VN30', 'TRIX_short_term3_VN30', 'TRIX_short_term7_VN30', 'TRIX_mid_term21_VN30', 'RSI_short_term3_VNINDEX', 'RSI_mid_term7_VNINDEX', 'ATR_VNINDEX', 'MACD_VNINDEX', 'Signal_Line_VNINDEX', 'Histogram_VNINDEX', 'return_day_VNINDEX', 'return_week_VNINDEX', 'return_month_VNINDEX', 'volatility_day_VNINDEX', 'return_day_std_VNINDEX', 'MFI_3_VNINDEX', 'MFI_7_VNINDEX', 'Momentum_3_VNINDEX', 'Momentum_7_VNINDEX', 'Momentum_21_VNINDEX', 'ROCR_3_VNINDEX', 'ROCR_7_VNINDEX', 'ROCR_21_VNINDEX', 'CCI_3_VNINDEX', 'CCI_7_VNINDEX', 'CCI_63_VNINDEX', 'Williams_R_21_VNINDEX', 'ADX_3_VNINDEX', 'ADX_7_VNINDEX', 'TRIX_short_term3_VNINDEX', 'TRIX_short_term7_VNINDEX', 'TRIX_mid_term21_VNINDEX', 'TRIX_mid_term63_VNINDEX', 'TRIX_long_term100_VNINDEX', 'RSI_short_term3_FPT', 'RSI_mid_term7_FPT', 'RSI_mid_term21_FPT', 'return_day_FPT', 'return_week_FPT', 'volatility_day_FPT', 'volatility_week_FPT', 'return_day_std_FPT', 'return_week_std_FPT', 'return_month_std_FPT', 'Momentum_3_FPT', 'Momentum_7_FPT', 'ROCR_3_FPT', 'ROCR_7_FPT', 'CCI_3_FPT', 'CCI_7_FPT', 'CCI_21_FPT', 'Williams_R_3_FPT', 'Williams_R_7_FPT', 'ADX_7_FPT', 'TRIX_short_term3_FPT']\n","Số cột cần loại bỏ: 221\n","Cột bị loại: ['Debt/Equity', 'Fixed Asset-To-Equity', 'Days Sales Outstanding', 'Cash Cycle', 'Current Ratio', 'Quick Ratio', 'Interest Coverage', 'P/Cash Flow', 'EPS (VND)', 'RSI_short_term3_VN30', 'RSI_mid_term7_VN30', 'RSI_mid_term21_VN30', 'ATR_VN30', 'MACD_VN30', 'Signal_Line_VN30', 'Histogram_VN30', 'return_day_VN30', 'return_week_VN30', 'return_month_VN30', 'volatility_day_VN30', 'high_minus_close_VN30', 'low_minus_open_VN30', 'return_day_std_VN30', 'MFI_3_VN30', 'MFI_7_VN30', 'Momentum_3_VN30', 'Momentum_7_VN30', 'Momentum_21_VN30', 'ROCR_3_VN30', 'ROCR_7_VN30', 'ROCR_21_VN30', 'CCI_3_VN30', 'CCI_7_VN30', 'CCI_21_VN30', 'CCI_63_VN30', 'Williams_R_3_VN30', 'Williams_R_7_VN30', 'Williams_R_21_VN30', 'Williams_R_63_VN30', 'Williams_R_100_VN30', 'ADX_3_VN30', 'ADX_7_VN30', 'TRIX_short_term3_VN30', 'TRIX_short_term7_VN30', 'TRIX_mid_term21_VN30', 'TRIX_mid_term63_VN30', 'TRIX_long_term100_VN30', 'RSI_short_term3_VNINDEX', 'RSI_mid_term7_VNINDEX', 'RSI_mid_term21_VNINDEX', 'ATR_VNINDEX', 'MACD_VNINDEX', 'Signal_Line_VNINDEX', 'Histogram_VNINDEX', 'return_day_VNINDEX', 'return_week_VNINDEX', 'return_month_VNINDEX', 'volatility_day_VNINDEX', 'high_minus_close_VNINDEX', 'low_minus_open_VNINDEX', 'return_day_std_VNINDEX', 'MFI_3_VNINDEX', 'MFI_7_VNINDEX', 'MFI_21_VNINDEX', 'MFI_100_VNINDEX', 'Momentum_3_VNINDEX', 'Momentum_7_VNINDEX', 'Momentum_21_VNINDEX', 'ROCR_3_VNINDEX', 'ROCR_7_VNINDEX', 'ROCR_21_VNINDEX', 'CCI_3_VNINDEX', 'CCI_7_VNINDEX', 'CCI_21_VNINDEX', 'CCI_63_VNINDEX', 'Williams_R_3_VNINDEX', 'Williams_R_7_VNINDEX', 'Williams_R_21_VNINDEX', 'Williams_R_63_VNINDEX', 'Williams_R_100_VNINDEX', 'ADX_3_VNINDEX', 'ADX_7_VNINDEX', 'ADX_21_VNINDEX', 'ADX_63_VNINDEX', 'ADX_100_VNINDEX', 'TRIX_short_term3_VNINDEX', 'TRIX_short_term7_VNINDEX', 'TRIX_mid_term21_VNINDEX', 'TRIX_mid_term63_VNINDEX', 'TRIX_long_term100_VNINDEX', 'RSI_short_term3_CMC', 'RSI_mid_term7_CMC', 'RSI_mid_term21_CMC', 'RSI_mid_term63_CMC', 'Histogram_CMC', 'return_day_CMC', 'return_week_CMC', 'return_month_CMC', 'volatility_day_CMC', 'volatility_week_CMC', 'return_day_std_CMC', 'return_week_std_CMC', 'MFI_3_CMC', 'MFI_7_CMC', 'MFI_21_CMC', 'MFI_63_CMC', 'MFI_100_CMC', 'Momentum_3_CMC', 'Momentum_7_CMC', 'Momentum_21_CMC', 'Momentum_63_CMC', 'Momentum_100_CMC', 'ROCR_3_CMC', 'ROCR_7_CMC', 'ROCR_21_CMC', 'ROCR_63_CMC', 'ROCR_100_CMC', 'CCI_3_CMC', 'CCI_7_CMC', 'CCI_21_CMC', 'Williams_R_3_CMC', 'Williams_R_7_CMC', 'Williams_R_21_CMC', 'Williams_R_63_CMC', 'ADX_3_CMC', 'ADX_7_CMC', 'ADX_21_CMC', 'TRIX_short_term3_CMC', 'TRIX_short_term7_CMC', 'TRIX_mid_term21_CMC', 'TRIX_mid_term63_CMC', 'TRIX_long_term100_CMC', 'Fixed Asset-To-Equity', 'Days Sales Outstanding', 'Current Ratio', 'Quick Ratio', 'Interest Coverage', 'RSI_short_term3_VN30', 'MACD_VN30', 'Signal_Line_VN30', 'Histogram_VN30', 'return_day_VN30', 'return_week_VN30', 'volatility_day_VN30', 'high_minus_close_VN30', 'low_minus_open_VN30', 'return_day_std_VN30', 'Momentum_3_VN30', 'Momentum_7_VN30', 'Momentum_21_VN30', 'ROCR_3_VN30', 'ROCR_7_VN30', 'ROCR_21_VN30', 'CCI_3_VN30', 'CCI_21_VN30', 'Williams_R_21_VN30', 'ADX_3_VN30', 'ADX_7_VN30', 'TRIX_short_term3_VN30', 'TRIX_short_term7_VN30', 'TRIX_long_term100_VN30', 'RSI_short_term3_VNINDEX', 'ATR_VNINDEX', 'MACD_VNINDEX', 'Signal_Line_VNINDEX', 'Histogram_VNINDEX', 'return_day_VNINDEX', 'return_week_VNINDEX', 'return_month_VNINDEX', 'volatility_day_VNINDEX', 'return_day_std_VNINDEX', 'MFI_3_VNINDEX', 'Momentum_3_VNINDEX', 'Momentum_7_VNINDEX', 'Momentum_21_VNINDEX', 'ROCR_3_VNINDEX', 'ROCR_7_VNINDEX', 'ROCR_21_VNINDEX', 'CCI_3_VNINDEX', 'CCI_63_VNINDEX', 'Williams_R_21_VNINDEX', 'ADX_3_VNINDEX', 'ADX_7_VNINDEX', 'ADX_63_VNINDEX', 'ADX_100_VNINDEX', 'TRIX_short_term3_VNINDEX', 'TRIX_short_term7_VNINDEX', 'RSI_short_term3_CMC', 'RSI_mid_term7_CMC', 'RSI_mid_term21_CMC', 'RSI_mid_term63_CMC', 'Histogram_CMC', 'return_day_CMC', 'return_week_CMC', 'return_month_CMC', 'volatility_day_CMC', 'return_day_std_CMC', 'MFI_3_CMC', 'MFI_7_CMC', 'MFI_21_CMC', 'MFI_63_CMC', 'Momentum_3_CMC', 'Momentum_7_CMC', 'Momentum_21_CMC', 'Momentum_63_CMC', 'Momentum_100_CMC', 'ROCR_3_CMC', 'ROCR_7_CMC', 'ROCR_21_CMC', 'ROCR_63_CMC', 'ROCR_100_CMC', 'CCI_3_CMC', 'CCI_7_CMC', 'CCI_21_CMC', 'Williams_R_3_CMC', 'Williams_R_7_CMC', 'Williams_R_21_CMC', 'Williams_R_63_CMC', 'ADX_7_CMC', 'TRIX_short_term3_CMC', 'TRIX_short_term7_CMC']\n"]}],"source":["FPT_after_filter = filter_features(FPT_after_analysis, 'FPT')\n","CMC_after_filter = filter_features(CMC_after_analysis, 'CMC')\n","FPT_after_filter.to_csv('FPT raw.csv', index = False)\n","CMC_after_filter.to_csv('CMC raw.csv', index = False)"]},{"cell_type":"markdown","source":["#LSTM"],"metadata":{"id":"7rZcxfhOZHAA"}},{"cell_type":"markdown","source":["##PreProcess"],"metadata":{"id":"4Xz9OOWY_yRd"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, PowerTransformer, MinMaxScaler, RobustScaler\n","from sklearn.pipeline import Pipeline\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","import torch.nn.functional as F\n","from sklearn.preprocessing import MinMaxScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch\n","from tqdm import tqdm\n","import optuna\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import pandas as pd\n","from copy import deepcopy\n","import torch\n","import random\n","class StockDataProcessor:\n","    def __init__(self, data, company_name, lookback, forecast_horizon,\n","                 val_ratio=0.1, test_ratio=0.1, batch_size=32):\n","        self.data = data\n","        self.company_name = company_name\n","        self.lookback = lookback\n","        self.forecast_horizon = forecast_horizon\n","        self.val_ratio = val_ratio\n","        self.test_ratio = test_ratio\n","        self.batch_size = batch_size\n","\n","        # Xử lý dữ liệu\n","        self._process_data()\n","\n","    def _process_data(self):\n","        \"\"\"Pipeline xử lý dữ liệu an toàn không bị leakage\"\"\"\n","        self._prepare_raw_data()\n","        self._split_raw_data()\n","        self._initialize_scalers()\n","        self._scale_data()\n","        self._create_sequences()\n","        self._create_dataloaders()\n","\n","    def _prepare_raw_data(self):\n","        \"\"\"Tách features và target từ dữ liệu gốc với làm mượt\"\"\"\n","        close_prices = self.data[f'Close_{self.company_name}'].values\n","        self.y_raw = close_prices\n","\n","        # Xử lý features\n","        self.X_raw = self.data.drop(columns=['Date']).values\n","\n","    def _split_raw_data(self):\n","        \"\"\"Chia dữ liệu thô thành train/val/test theo thời gian\"\"\"\n","        n_samples = len(self.X_raw)\n","        train_end = int(n_samples * (1 - self.val_ratio - self.test_ratio))\n","        val_end = int(n_samples * (1 - self.test_ratio))\n","\n","        self.X_train_raw = self.X_raw[:train_end]\n","        self.y_train_raw = self.y_raw[:train_end]\n","        self.X_val_raw = self.X_raw[train_end:val_end]\n","        self.y_val_raw = self.y_raw[train_end:val_end]\n","        self.X_test_raw = self.X_raw[val_end:]\n","        self.y_test_raw = self.y_raw[val_end:]\n","\n","    def _initialize_scalers(self):\n","        \"\"\"Khởi tạo scaler và chỉ fit trên tập train\"\"\"\n","        self.x_scaler = MinMaxScaler(feature_range=(-1,1))\n","        self.x_scaler.fit(self.X_train_raw)\n","\n","        self.y_scaler = Pipeline([\n","            ('minmax', MinMaxScaler(feature_range=(-1, 1)))\n","        ])\n","        self.y_scaler.fit(self.y_train_raw.reshape(-1, 1))\n","\n","    def _scale_data(self):\n","        \"\"\"Áp dụng scaling riêng cho từng tập\"\"\"\n","        self.X_train = self.x_scaler.transform(self.X_train_raw)\n","        self.X_val = self.x_scaler.transform(self.X_val_raw)\n","        self.X_test = self.x_scaler.transform(self.X_test_raw)\n","\n","        self.y_train = self.y_scaler.transform(self.y_train_raw.reshape(-1, 1)).flatten()\n","        self.y_val = self.y_scaler.transform(self.y_val_raw.reshape(-1, 1)).flatten()\n","        self.y_test = self.y_scaler.transform(self.y_test_raw.reshape(-1, 1)).flatten()\n","\n","    def _create_sequences(self):\n","        \"\"\"Tạo sequences cửa sổ trượt cho từng tập riêng biệt\"\"\"\n","        def create_sequences(X_data, y_data):\n","            X_seq, y_seq = [], []\n","            for i in range(self.lookback, len(X_data)):\n","                X_seq.append(X_data[i-self.lookback:i])\n","                y_seq.append(y_data[i])\n","            return np.array(X_seq), np.array(y_seq)\n","\n","        self.X_train_seq, self.y_train_seq = create_sequences(self.X_train, self.y_train)\n","        self.X_val_seq, self.y_val_seq = create_sequences(self.X_val, self.y_val)\n","        self.X_test_seq, self.y_test_seq = create_sequences(self.X_test, self.y_test)\n","\n","    def _create_dataloaders(self):\n","        \"\"\"Tạo DataLoaders từ tensor\"\"\"\n","        train_data = TensorDataset(\n","            torch.FloatTensor(self.X_train_seq),\n","            torch.FloatTensor(self.y_train_seq))\n","\n","        val_data = TensorDataset(\n","            torch.FloatTensor(self.X_val_seq),\n","            torch.FloatTensor(self.y_val_seq))\n","\n","        test_data = TensorDataset(\n","            torch.FloatTensor(self.X_test_seq),\n","            torch.FloatTensor(self.y_test_seq))\n","\n","        self.train_loader = DataLoader(train_data, batch_size=self.batch_size, shuffle=True, pin_memory=True)\n","        self.val_loader = DataLoader(val_data, batch_size=self.batch_size, shuffle=False, pin_memory=True)\n","        self.test_loader = DataLoader(test_data, batch_size=self.batch_size, shuffle=False, pin_memory=True)\n","\n","    def inverse_transform_y(self, y):\n","        \"\"\"Chuyển đổi y đã scaled về giá trị gốc\"\"\"\n","        return self.y_scaler.inverse_transform(y.reshape(-1, 1)).flatten()"],"metadata":{"id":"ejInp9XV_7p3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZJl3TpRFFAYT"},"source":["## LSTM Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yYh9h2qKFzWr"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class GaussianNoise(nn.Module):\n","    \"\"\"Lớp Gaussian Noise với decay, phù hợp dữ liệu [-1, 1]\"\"\"\n","    def __init__(self, std=0.1, decay_factor=0.97, min_std=0.01, clip=True):\n","        super().__init__()\n","        self.init_std = std\n","        self.current_std = std\n","        self.decay_factor = decay_factor\n","        self.min_std = min_std\n","        self.clip = clip\n","\n","    def decay(self):\n","        \"\"\"Giảm cường độ nhiễu sau mỗi epoch\"\"\"\n","        self.current_std = max(self.current_std * self.decay_factor, self.min_std)\n","\n","    def forward(self, x):\n","        if self.training and self.current_std > 0:\n","            noise = torch.randn_like(x) * self.current_std\n","            x_noisy = x + noise\n","            return torch.clamp(x_noisy, -1.0, 1.0) if self.clip else x_noisy\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6jb4IW5OGk--"},"outputs":[],"source":["#Attention 1\n","class FeatureAttention(nn.Module):\n","    def __init__(self, dim, reduction_ratio=4):\n","        super().__init__()\n","        reduced_dim = max(dim // reduction_ratio, 16)\n","\n","        self.attn = nn.Sequential(\n","            nn.Linear(dim, reduced_dim),\n","            nn.SiLU(),\n","            nn.Linear(reduced_dim, dim),\n","            nn.Mish()\n","        )\n","\n","    def forward(self, x):\n","        return x * self.attn(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5hKoTWlVGov0"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MultiScaleTemporal(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, scales, dropout=0.1):\n","        super().__init__()\n","        self.scales = scales\n","        self.dropout = dropout\n","        n_scales = len(scales)\n","        per_scale, remainder = divmod(hidden_dim, n_scales)\n","        self.conv_dims = [per_scale + (1 if i < remainder else 0) for i in range(n_scales)]\n","\n","        self.convs = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv1d(input_dim, dim, kernel_size=k, padding=k // 2),\n","                nn.Tanh(),\n","                nn.Dropout(dropout)\n","            )\n","            for k, dim in zip(scales, self.conv_dims)\n","        ])\n","\n","        self.weights = nn.Parameter(torch.zeros(n_scales))\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: Tensor [batch, seq_len, input_dim]\n","        \"\"\"\n","        x_t = x.transpose(1, 2)\n","\n","        scale_features = []\n","        for conv in self.convs:\n","            conv_out = conv(x_t).transpose(1, 2)\n","            scale_features.append(conv_out)\n","\n","        weights = F.softmax(self.weights, dim=0)\n","\n","        fused = torch.cat([w * feat for w, feat in zip(weights, scale_features)], dim=-1)\n","\n","        output = torch.cat([fused, x], dim=-1)\n","\n","        return torch.tanh(output)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p470rJaaGsIR"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class HierarchicalLSTM(nn.Module):\n","    def __init__(self, n_features=165, hidden_dim=64, num_layers=1, dropout_rate=0.3):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.alpha = nn.Parameter(torch.tensor(0.5), requires_grad=True)\n","\n","        # === Feature Extraction ===\n","        self.input_noise = GaussianNoise(std=0.005)\n","        self.feature_noise = GaussianNoise(std=0.001)\n","\n","        self.feature_selector = nn.Sequential(\n","            nn.Linear(n_features, hidden_dim),\n","            nn.Mish(),\n","            nn.LayerNorm(hidden_dim),\n","            FeatureAttention(hidden_dim),\n","            nn.Dropout(0.2)\n","        )\n","\n","        # === LSTM ===\n","        self.pre_lstm_norm = nn.LayerNorm(hidden_dim)\n","        self.lstm_noise = GaussianNoise(std=0.01)\n","        self.lstm = nn.LSTM(\n","            input_size=hidden_dim,\n","            hidden_size=hidden_dim,\n","            num_layers=num_layers,\n","            dropout=dropout_rate if num_layers > 1 else 0,\n","            batch_first=True,\n","            bidirectional=False\n","        )\n","        self.lstm_layer_norms = nn.ModuleList([nn.LayerNorm(hidden_dim) for _ in range(num_layers)])\n","\n","        # === Attention ===\n","        self.attn_noise = GaussianNoise(std=0.02)\n","        self.attention = nn.MultiheadAttention(\n","            embed_dim=hidden_dim,\n","            num_heads=8,\n","            dropout=0.3,\n","            batch_first=True\n","        )\n","        self.post_attn_norm = nn.LayerNorm(hidden_dim)\n","        self.attn_dropout = nn.Dropout(0.3)\n","\n","        # Initialize attention weights\n","        for name, param in self.attention.named_parameters():\n","            if 'weight' in name:\n","                nn.init.xavier_uniform_(param, gain=0.5)\n","\n","        self.attn_residual = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim * 2),\n","            nn.Mish(),\n","            nn.LayerNorm(hidden_dim * 2),\n","            nn.Linear(hidden_dim * 2, hidden_dim),\n","            nn.LayerNorm(hidden_dim)\n","        )\n","        nn.init.xavier_uniform_(self.attn_residual[0].weight, gain=0.01)\n","        nn.init.zeros_(self.attn_residual[0].bias)\n","\n","        # === Multi-Scale Temporal Processing ===\n","        self.scale_noise = GaussianNoise(std=0.03)\n","        self.temporal_scaler = MultiScaleTemporal(\n","            input_dim=hidden_dim,\n","            hidden_dim=hidden_dim * 2,\n","            scales=[1, 3, 7, 21, 45],\n","            dropout=0.2\n","        )\n","\n","        # === Output Layer ===\n","        self.output_layer = nn.Sequential(\n","            nn.Linear(hidden_dim * 3, hidden_dim * 4),\n","            nn.Mish(),\n","            nn.LayerNorm(hidden_dim * 4),\n","            nn.Dropout(0.3),\n","            nn.Linear(hidden_dim * 4, hidden_dim * 2),\n","            nn.Mish(),\n","            nn.LayerNorm(hidden_dim * 2),\n","            nn.Dropout(0.2),\n","            nn.Linear(hidden_dim * 2, 1),\n","        )\n","\n","    def log_std(self, name, tensor):\n","        std_value = tensor.std().item()\n","        with open(\"std_log.txt\", \"a\") as f:\n","            f.write(f\"{name}: std={std_value:.6f}\\n\")\n","\n","    def forward(self, x):\n","        batch_size, seq_len, _ = x.shape\n","\n","        # === Feature Extraction ===\n","        x = self.input_noise(x)\n","        features = self.feature_selector(x)\n","        features = self.feature_noise(features)\n","        self.log_std(\"Feature\", features)\n","\n","        # === LSTM ===\n","        features = self.lstm_noise(features)\n","        features = self.pre_lstm_norm(features)\n","        lstm_out, _ = self.lstm(features)\n","        self.log_std(\"LSTM raw\", lstm_out)\n","\n","        if self.num_layers > 1:\n","            lstm_out = self.lstm_layer_norms[-1](lstm_out)\n","        self.log_std(\"LSTM normed\", lstm_out)\n","\n","        lstm_out = lstm_out + features\n","\n","        # === Attention ===\n","        attn_input = self.attn_noise(lstm_out)\n","\n","        # Tạo causal mask\n","        causal_mask = torch.triu(\n","            torch.ones(seq_len, seq_len, device=attn_input.device),\n","            diagonal=1\n","        ).bool()\n","\n","        attn_out, _ = self.attention(\n","            query=attn_input,\n","            key=attn_input,\n","            value=attn_input,\n","            attn_mask=causal_mask\n","        )\n","\n","        attn_residual = torch.clamp(self.attn_residual(attn_input), -3.0, 3.0)\n","\n","        # Skip connection + LayerNorm\n","        attn_out = attn_out + attn_residual * torch.sigmoid(self.alpha)\n","        attn_out = self.attn_dropout(attn_out)\n","\n","        self.log_std(\"Attention\", attn_out)\n","\n","        # === Temporal Fusion ===\n","        fused = self.temporal_scaler(self.scale_noise(attn_out))\n","        self.log_std(\"Temporal fused\", fused)\n","\n","        # === Output ===\n","        fused_last = fused[:, -1, :]\n","        self.log_std(\"Fused last step\", fused_last)\n","\n","        output = self.output_layer(fused_last)\n","        self.log_std(\"Output\", output)\n","\n","        return output"]},{"cell_type":"markdown","source":["##Train LSTM"],"metadata":{"id":"2rv5t1Ns_hm0"}},{"cell_type":"code","source":["class StockCombinedLoss(nn.Module):\n","    def __init__(self, alpha=0.5, delta=1e-3, gamma=0.1, smooth=1e-6):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.delta = delta\n","        self.gamma = gamma\n","        self.smooth = smooth\n","\n","        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n","\n","    def forward(self, price_preds, price_targets):\n","        # Đảm bảo kích thước đúng\n","        price_preds = price_preds.view(-1)\n","        price_targets = price_targets.view(-1)\n","\n","        # ==== Huber loss để giảm ảnh hưởng của outliers ====\n","        mse_loss = F.huber_loss(price_preds, price_targets)\n","\n","        # ==== Direction component cải tiến ====\n","        pred_diffs = price_preds[1:] - price_preds[:-1]\n","        true_diffs = price_targets[1:] - price_targets[:-1]\n","\n","        # Chỉ lấy các chuyển động đủ lớn\n","        meaningful = true_diffs.abs() > self.delta\n","        meaningful_mask = meaningful.float()\n","\n","        if meaningful.sum() > 0:\n","            # Label smoothing để ổn định training\n","            direction_labels = (true_diffs[meaningful] > 0).float()\n","            direction_labels = direction_labels.clamp(self.smooth, 1-self.smooth)\n","\n","            # BCE loss với trọng số cho các mẫu khó\n","            direction_preds = pred_diffs[meaningful]\n","            bce_loss = self.bce(direction_preds, direction_labels)\n","\n","            # Thêm penalty cho các dự đoán chuyển động ngược chiều\n","            wrong_direction = ((pred_diffs[meaningful] * true_diffs[meaningful]) < 0).float()\n","            direction_penalty = (wrong_direction * bce_loss.detach()).mean()\n","\n","            bce_loss = bce_loss.mean() + self.gamma * direction_penalty\n","        else:\n","            bce_loss = torch.tensor(0.0, device=price_preds.device)\n","\n","        # ==== Thêm thành phần tương quan ====\n","        pred_norm = price_preds - price_preds.mean()\n","        true_norm = price_targets - price_targets.mean()\n","        correlation = (pred_norm * true_norm).sum() / (\n","            torch.sqrt((pred_norm.pow(2).sum() + self.smooth) *\n","                      (true_norm.pow(2).sum() + self.smooth))\n","        )\n","        corr_loss = 1 - correlation\n","\n","        # ==== Tổng hợp loss ====\n","        total_loss = (\n","            self.alpha * mse_loss +\n","            (0.8 - 0.3*self.alpha) * bce_loss +\n","            (0.2 - 0.1*self.alpha) * corr_loss\n","        )\n","\n","        return total_loss"],"metadata":{"id":"Oxt9x4fKA6__"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Train:\n","    def __init__(self, model, train_loader, val_loader,\n","                 trial=None,\n","                 learning_rate=1e-4,\n","                 weight_decay=1e-5,\n","                 epochs=50,\n","                 early_stopping_patience=10,\n","                 grad_clip=2.0,\n","                 betas=(0.9, 0.999),\n","                 eps=1e-8,\n","                 pct_start=0.3,\n","                 amp_enabled=True,\n","                 device=None,\n","                 scaler_y=None,\n","                 alpha=0.1,\n","                 delta=1e-03,\n","                 gamma=0.1,\n","                 smooth=1e-06):\n","        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.model = model.to(self.device)\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.trial = trial\n","        self.scaler_y = scaler_y\n","\n","        self.best_model_weights = None\n","        self.best_epoch = 0\n","\n","        self.learning_rate = learning_rate\n","        self.weight_decay = weight_decay\n","        self.epochs = epochs\n","        self.early_stopping_patience = early_stopping_patience\n","        self.grad_clip = grad_clip\n","        self.betas = betas\n","        self.eps = eps\n","        self.pct_start = pct_start\n","        self.amp_enabled = amp_enabled\n","        self.alpha = alpha\n","        self.delta=delta\n","        self.gamma=gamma\n","        self.smooth=smooth\n","\n","        self._init_components()\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.best_val_loss = float('inf')\n","\n","    def _init_components(self):\n","        self.loss_fn = StockCombinedLoss(alpha = self.alpha, delta=self.delta, gamma=self.gamma, smooth=self.smooth)\n","        self.optimizer = torch.optim.AdamW(\n","            self.model.parameters(),\n","            lr=self.learning_rate,\n","            weight_decay=self.weight_decay,\n","            betas=self.betas,\n","            eps=self.eps\n","        )\n","        self.scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","            self.optimizer,\n","            max_lr=self.learning_rate,\n","            steps_per_epoch=len(self.train_loader),\n","            epochs=self.epochs,\n","            pct_start=self.pct_start,\n","            anneal_strategy='cos',\n","            final_div_factor=1e4\n","        )\n","        self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp_enabled and self.device.type == 'cuda')\n","        self.early_stopping_counter = 0\n","\n","    def _train_epoch(self):\n","        self.model.train()\n","        running_loss = 0.0\n","\n","        for batch_idx, (X, y) in enumerate(self.train_loader):\n","            X, y = X.to(self.device), y.to(self.device)\n","\n","            if self.scaler_y:\n","                y = self.scaler_y.transform(y.cpu().numpy()).astype(np.float32)\n","                y = torch.tensor(y).to(self.device)\n","\n","            self.optimizer.zero_grad(set_to_none=True)\n","\n","            with torch.autocast(device_type=self.device.type, enabled=self.amp_enabled):\n","                preds = self.model(X)\n","                y = y.unsqueeze(1)\n","                loss = self.loss_fn(preds, y)\n","\n","            self.scaler.scale(loss).backward()\n","\n","            if self.grad_clip:\n","                self.scaler.unscale_(self.optimizer)\n","                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=self.grad_clip)\n","\n","            self.scaler.step(self.optimizer)\n","            self.scaler.update()\n","            self.scheduler.step()\n","\n","            running_loss += loss.item()\n","\n","        avg_loss = running_loss / len(self.train_loader)\n","        self.train_losses.append(avg_loss)\n","        return avg_loss\n","\n","    def _validate(self):\n","        self.model.eval()\n","        total_loss = 0.0\n","        all_preds = []\n","        all_targets = []\n","\n","        with torch.no_grad():\n","            for X, y in self.val_loader:\n","                X, y = X.to(self.device), y.to(self.device)\n","\n","                if self.scaler_y:\n","                    y = self.scaler_y.transform(y.cpu().numpy()).astype(np.float32)\n","                    y = torch.tensor(y).to(self.device)\n","\n","                with torch.autocast(device_type=self.device.type, enabled=self.amp_enabled):\n","                    preds = self.model(X)\n","                    y = y.unsqueeze(1)\n","                    loss = self.loss_fn(preds, y)\n","\n","                total_loss += loss.item()\n","                all_preds.append(preds)\n","                all_targets.append(y)\n","\n","        all_preds = torch.cat(all_preds)\n","        all_targets = torch.cat(all_targets)\n","        mae = torch.abs(all_preds - all_targets).mean().item()\n","        mse = F.mse_loss(all_preds, all_targets).item()\n","\n","        avg_loss = total_loss / len(self.val_loader)\n","        self.val_losses.append(avg_loss)\n","        return avg_loss, mae, mse\n","\n","    def train(self):\n","        try:\n","            for epoch in range(self.epochs):\n","                train_loss = self._train_epoch()\n","                val_loss, mae, mse = self._validate()\n","\n","                print(f\"[Epoch {epoch+1}/{self.epochs}] Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | MAE: {mae:.4f} | MSE: {mse:.4f}\")\n","\n","                if self.trial:\n","                    self.trial.report(val_loss, epoch)\n","                    if self.trial.should_prune():\n","                        raise optuna.exceptions.TrialPruned()\n","\n","                if val_loss < self.best_val_loss:\n","                    self.best_val_loss = val_loss\n","                    self.best_model_weights = deepcopy(self.model.state_dict())\n","                    self.best_epoch = epoch\n","                    self.early_stopping_counter = 0\n","                else:\n","                    self.early_stopping_counter += 1\n","                    if self.early_stopping_counter >= self.early_stopping_patience:\n","                        print(f\"Early stopping triggered at epoch {epoch+1}. Best epoch: {self.best_epoch+1}\")\n","                        break\n","\n","            if self.best_model_weights:\n","                self.model.load_state_dict(self.best_model_weights)\n","            torch.save(self.model.state_dict(), 'best_model.pth')\n","\n","            return self.best_val_loss\n","\n","        except Exception as e:\n","            print(f\"Training interrupted: {str(e)}\")\n","            return float('inf')\n","\n","def objective(trial):\n","    torch.cuda.empty_cache()\n","\n","    SEED = 42 + trial.number\n","    torch.manual_seed(SEED)\n","    np.random.seed(SEED)\n","    random.seed(SEED)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    model_params = {\n","        'hidden_dim': trial.suggest_categorical('hidden_dim', [32, 64, 128, 256, 512]),\n","        'num_layers': trial.suggest_int('num_layers', 1, 3),\n","        'dropout_rate': trial.suggest_float('dropout_rate', 0, 0.5, step=0.05),\n","    }\n","\n","    training_params = {\n","        'learning_rate': trial.suggest_float('lr', 1e-6, 1e-2, log=True),\n","        'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True),\n","        'grad_clip': trial.suggest_float('grad_clip', 0.1, 2.0),\n","        'pct_start': trial.suggest_float('pct_start', 0.1, 0.5),\n","        'betas': (\n","            trial.suggest_float('beta1', 0.8, 0.999),\n","            trial.suggest_float('beta2', 0.9, 0.9999)\n","        ),\n","          'alpha' : trial.suggest_float(\"alpha\", 0.5, 1, step = 0.05),\n","          'delta' : trial.suggest_float(\"delta\", 1e-4, 1e-2, log=True),\n","          'gamma' : trial.suggest_float(\"gamma\", 0.05, 0.3, step = 0.05),\n","          'smooth' : trial.suggest_float(\"smooth\", 1e-7, 1e-3, log=True)\n","\n","    }\n","\n","    model = HierarchicalLSTM(**model_params)\n","\n","    for layer in model.children():\n","        if hasattr(layer, 'reset_parameters'):\n","            layer.reset_parameters()\n","\n","    trainer = Train(\n","        model=model,\n","        train_loader=train_loader,\n","        val_loader=val_loader,\n","        trial=trial,\n","        epochs=100,\n","        early_stopping_patience=15,\n","        **training_params\n","    )\n","\n","    val_loss = trainer.train()\n","\n","    trial.set_user_attr(\"train_losses\", trainer.train_losses)\n","    trial.set_user_attr(\"val_losses\", trainer.val_losses)\n","\n","    return val_loss"],"metadata":{"id":"zatLaBQJ_krB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##LSTM Day3"],"metadata":{"id":"LNA9rR5k_Z4K"}},{"cell_type":"code","source":["#Lấy dữ liệu\n","data = pd.read_csv('FPT raw.csv')\n","\n","#Tham số chính\n","BATCHSIZE = 128\n","WINDOWSIZE = 30\n","FORECASTHORIZON = 3\n","INPUTSIZE = 165\n","\n","#Lấy train, val, test\n","train_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).train_loader\n","val_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).val_loader\n","test_loader_day3 = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).test_loader\n","scaler_y_day3 = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).y_scaler\n","\n","#Huấn luyện mô hình\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","best_params_day3 = study.best_params\n","\n","best_model_params = {\n","    'hidden_dim': best_params_day3['hidden_dim'],\n","    'num_layers': best_params_day3['num_layers'],\n","    'dropout_rate': best_params_day3['dropout_rate'],\n","}\n","model_day3 = HierarchicalLSTM(**best_model_params)\n","\n","best_training_params = {\n","    'learning_rate': best_params_day3['lr'],\n","    'weight_decay': best_params_day3['weight_decay'],\n","    'grad_clip': best_params_day3['grad_clip'],\n","    'pct_start': best_params_day3['pct_start'],\n","    'betas': (best_params_day3['beta1'], best_params_day3['beta2']),\n","    'alpha' : best_params_day3['alpha'],\n","    'delta' : best_params_day3['delta'],\n","    'gamma' : best_params_day3['gamma'],\n","    'smooth' : best_params_day3['smooth'],\n","}\n","\n","# 4. Huấn luyện thật\n","trainer = Train(\n","    model=model_day3,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=100,\n","    early_stopping_patience=15,\n","    **best_training_params\n",")\n","\n","val_loss = trainer.train()\n","print(\"Final best validation loss:\", val_loss)\n","\n","def evaluate_model(model, X_test, y_test, scaler_X, scaler_Y, forecast_horizon, device=None):\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    model.eval()\n","    model.to(device)\n","    X_test = X_test.reshape(-1, WINDOWSIZE, model.feature_selector[0].in_features)\n","\n","    with torch.no_grad():\n","        X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n","        preds = model(X_test_tensor).cpu().numpy()\n","\n","    preds_inv = scaler_Y.inverse_transform(preds.reshape(-1, 1))\n","    y_test_inv = scaler_Y.inverse_transform(y_test.reshape(-1, 1))\n","\n","    rmse = np.sqrt(mean_squared_error(y_test_inv, preds_inv))\n","    mae = mean_absolute_error(y_test_inv, preds_inv)\n","    r2 = r2_score(y_test_inv, preds_inv)\n","\n","    print(f\"RMSE: {rmse:.4f}\")\n","    print(f\"MAE: {mae:.4f}\")\n","    print(f\"R2: {r2:.4f}\")\n","\n","    # Vẽ đồ thị\n","    plt.plot(y_test_inv, label='True Price')\n","    plt.plot(preds_inv, label='Predicted Price')\n","    plt.title('Actual vs Predicted Stock Price')\n","    plt.xlabel('Timestep')\n","    plt.ylabel('Price')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","    return rmse, mae, r2\n","\n","\n","x_val_scaled = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON, batch_size=BATCHSIZE).X_val_seq\n","y_val_scaled = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON, batch_size=BATCHSIZE).y_val_seq\n","scaler_x = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON, batch_size=BATCHSIZE).x_scaler\n","scaler_y = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON, batch_size=BATCHSIZE).y_scaler\n","\n","rmse, mae, r2 = evaluate_model(model_day3, x_val_scaled, y_val_scaled, scaler_x, scaler_y, FORECASTHORIZON)\n","print(rmse, mae, r2)"],"metadata":{"id":"8ykqV3h__--6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##LSTM Day7"],"metadata":{"id":"MlecN9_pHWAe"}},{"cell_type":"code","source":["#Lấy dữ liệu\n","data = pd.read_csv('FPT raw.csv')\n","\n","#Tham số chính\n","BATCHSIZE = 32\n","WINDOWSIZE = 30\n","FORECASTHORIZON = 7\n","INPUTSIZE = 165\n","\n","#Lấy train, val, test\n","train_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).train_loader\n","val_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).val_loader\n","test_loader_day7 = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).test_loader\n","scaler_y_day7 = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).y_scaler\n","\n","\n","#Huấn luyện mô hình\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","best_params_day7 = study.best_params\n","best_model_params = {\n","    'hidden_dim': best_params_day7['hidden_dim'],\n","    'num_layers': best_params_day7['num_layers'],\n","    'dropout_rate': best_params_day7['dropout_rate'],\n","}\n","model_day7 = HierarchicalLSTM(**best_model_params)\n","\n","best_training_params = {\n","    'learning_rate': best_params_day7['lr'],\n","    'weight_decay': best_params_day7['weight_decay'],\n","    'grad_clip': best_params_day7['grad_clip'],\n","    'pct_start': best_params_day7['pct_start'],\n","    'betas': (best_params_day7['beta1'], best_params_day7['beta2']),\n","    'alpha' : best_params_day7['alpha'],\n","    'delta' : best_params_day7['delta'],\n","    'gamma' : best_params_day7['gamma'],\n","    'smooth' : best_params_day7['smooth'],\n","}\n","\n","# 4. Huấn luyện thật\n","trainer = Train(\n","    model=model_day7,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=100,\n","    early_stopping_patience=15,\n","    **best_training_params\n",")\n","\n","val_loss = trainer.train()\n","print(\"Final best validation loss:\", val_loss)\n","\n","#Lấy dữ liệu\n","data = pd.read_csv('FPT raw.csv')\n","\n","#Tham số chính\n","BATCHSIZE = 32\n","WINDOWSIZE = 30\n","FORECASTHORIZON = 7\n","INPUTSIZE = 165\n","\n","#Lấy train, val, test\n","train_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).train_loader\n","val_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).val_loader\n","test_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).test_loader\n","scaler_y = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).y_scaler\n","\n","\n","def evaluate_model(model, X_test, y_test, scaler_X, scaler_Y, forecast_horizon, device=None):\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    model.eval()\n","    model.to(device)\n","    X_test = X_test.reshape(-1, WINDOWSIZE, model.feature_selector[0].in_features)\n","\n","    with torch.no_grad():\n","        X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n","        preds = model(X_test_tensor).cpu().numpy()\n","\n","    preds_inv = scaler_Y.inverse_transform(preds.reshape(-1, 1))\n","    y_test_inv = scaler_Y.inverse_transform(y_test.reshape(-1, 1))\n","\n","    rmse = np.sqrt(mean_squared_error(y_test_inv, preds_inv))\n","    mae = mean_absolute_error(y_test_inv, preds_inv)\n","    r2 = r2_score(y_test_inv, preds_inv)\n","\n","    print(f\"RMSE: {rmse:.4f}\")\n","    print(f\"MAE: {mae:.4f}\")\n","    print(f\"R2: {r2:.4f}\")\n","\n","    plt.plot(y_test_inv, label='True Price')\n","    plt.plot(preds_inv, label='Predicted Price')\n","    plt.title('Actual vs Predicted Stock Price')\n","    plt.xlabel('Timestep')\n","    plt.ylabel('Price')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","    return rmse, mae, r2\n","\n","\n","x_val_scaled = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON, batch_size=BATCHSIZE).X_val_seq\n","y_val_scaled = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON, batch_size=BATCHSIZE).y_val_seq\n","scaler_x = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON, batch_size=BATCHSIZE).x_scaler\n","scaler_y = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON, batch_size=BATCHSIZE).y_scaler\n","\n","rmse, mae, r2 = evaluate_model(model_day7, x_val_scaled, y_val_scaled, scaler_x, scaler_y, FORECASTHORIZON)\n","print(rmse, mae, r2)"],"metadata":{"id":"W7AOdlJjJ8tr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##LSTM Day 21"],"metadata":{"id":"fBgLtNg8vOgG"}},{"cell_type":"code","source":["#Lấy dữ liệu\n","data = pd.read_csv('FPT raw.csv')\n","\n","#Tham số chính\n","BATCHSIZE = 64\n","WINDOWSIZE = 40\n","FORECASTHORIZON = 21\n","INPUTSIZE = 165\n","\n","#Lấy train, val, test\n","train_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).train_loader\n","val_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).val_loader\n","test_loader_day21 = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).test_loader\n","scaler_y_day21 = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).y_scaler\n","\n","\n","#Huấn luyện mô hình\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","best_params_day21 = study.best_params\n","\n","best_model_params = {\n","    'hidden_dim': best_params_day21['hidden_dim'],\n","    'num_layers': best_params_day21['num_layers'],\n","    'dropout_rate': best_params_day21['dropout_rate'],\n","}\n","model_day21 = HierarchicalLSTM(**best_model_params)\n","\n","best_training_params = {\n","    'learning_rate': best_params_day21['lr'],\n","    'weight_decay': best_params_day21['weight_decay'],\n","    'grad_clip': best_params_day21['grad_clip'],\n","    'pct_start': best_params_day21['pct_start'],\n","    'betas': (best_params_day21['beta1'], best_params_day21['beta2']),\n","    'alpha' : best_params_day21['alpha'],\n","    'delta' : best_params_day21['delta'],\n","    'gamma' : best_params_day21['gamma'],\n","    'smooth' : best_params_day21['smooth'],\n","}\n","\n","# 4. Huấn luyện thật\n","trainer = Train(\n","    model=model_day21,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=100,\n","    early_stopping_patience=15,\n","    **best_training_params\n",")\n","\n","val_loss = trainer.train()\n","print(\"Final best validation loss:\", val_loss)\n","\n","def evaluate_model(model, X_test, y_test, scaler_X, scaler_Y, forecast_horizon, device=None):\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    model.eval()\n","    model.to(device)\n","    X_test = X_test.reshape(-1, WINDOWSIZE, model.feature_selector[0].in_features)\n","\n","    with torch.no_grad():\n","        X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n","        preds = model(X_test_tensor).cpu().numpy()\n","\n","    # Đảo ngược chuẩn hóa\n","    preds_inv = scaler_Y.inverse_transform(preds.reshape(-1, 1))\n","    y_test_inv = scaler_Y.inverse_transform(y_test.reshape(-1, 1))\n","\n","    # Đánh giá trực tiếp trên từng bước dự báo\n","    rmse = np.sqrt(mean_squared_error(y_test_inv, preds_inv))\n","    mae = mean_absolute_error(y_test_inv, preds_inv)\n","    r2 = r2_score(y_test_inv, preds_inv)\n","\n","    print(f\"RMSE: {rmse:.4f}\")\n","    print(f\"MAE: {mae:.4f}\")\n","    print(f\"R2: {r2:.4f}\")\n","\n","    # Vẽ đồ thị\n","    plt.plot(y_test_inv, label='True Price')\n","    plt.plot(preds_inv, label='Predicted Price')\n","    plt.title('Actual vs Predicted Stock Price')\n","    plt.xlabel('Timestep')\n","    plt.ylabel('Price')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","    return rmse, mae, r2\n","\n","\n","x_val_scaled = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=21, batch_size=BATCHSIZE).X_val_seq\n","y_val_scaled = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=21, batch_size=BATCHSIZE).y_val_seq\n","scaler_x = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=21, batch_size=BATCHSIZE).x_scaler\n","scaler_y = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=21, batch_size=BATCHSIZE).y_scaler\n","\n","rmse, mae, r2 = evaluate_model(model_day21, x_val_scaled, y_val_scaled, scaler_x, scaler_y, FORECASTHORIZON)\n","print(rmse, mae, r2)"],"metadata":{"id":"T6QgUF2SvP-o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##LSTM Day63"],"metadata":{"id":"MaCqLnLhXl2n"}},{"cell_type":"code","source":["#Lấy dữ liệu\n","data = pd.read_csv('FPT raw.csv')\n","\n","#Tham số chính\n","BATCHSIZE = 64\n","WINDOWSIZE = 90\n","FORECASTHORIZON = 63\n","INPUTSIZE = 165\n","\n","#Lấy train, val, test\n","train_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).train_loader\n","val_loader = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).val_loader\n","test_loader_day63 = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).test_loader\n","scaler_y_day63 = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=FORECASTHORIZON).y_scaler\n","\n","#Huấn luyện mô hình\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=100)\n","best_params_day63 = study.best_params\n","\n","best_model_params = {\n","    'hidden_dim': best_params_day63['hidden_dim'],\n","    'num_layers': best_params_day63['num_layers'],\n","    'dropout_rate': best_params_day63['dropout_rate'],\n","}\n","model_day63 = HierarchicalLSTM(**best_model_params)\n","\n","best_training_params = {\n","    'learning_rate': best_params_day63['lr'],\n","    'weight_decay': best_params_day63['weight_decay'],\n","    'grad_clip': best_params_day63['grad_clip'],\n","    'pct_start': best_params_day63['pct_start'],\n","    'betas': (best_params_day63['beta1'], best_params_day63['beta2']),\n","    'alpha' : best_params_day63['alpha'],\n","    'delta' : best_params_day63['delta'],\n","    'gamma' : best_params_day63['gamma'],\n","}\n","\n","# 4. Huấn luyện thật\n","trainer = Train(\n","    model=model_day63,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=100,\n","    early_stopping_patience=15,\n","    **best_training_params\n",")\n","\n","val_loss = trainer.train()\n","print(\"Final best validation loss:\", val_loss)\n","\n","def evaluate_model(model, X_test, y_test, scaler_X, scaler_Y, forecast_horizon, device=None):\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    model.eval()\n","    model.to(device)\n","    X_test = X_test.reshape(-1, WINDOWSIZE, model.feature_selector[0].in_features)\n","\n","    with torch.no_grad():\n","        X_test_tensor = torch.tensor(X_test, dtype=torch.float32, device=device)\n","        preds = model(X_test_tensor).cpu().numpy()\n","\n","    preds_inv = scaler_Y.inverse_transform(preds.reshape(-1, 1))\n","    y_test_inv = scaler_Y.inverse_transform(y_test.reshape(-1, 1))\n","\n","    rmse = np.sqrt(mean_squared_error(y_test_inv, preds_inv))\n","    mae = mean_absolute_error(y_test_inv, preds_inv)\n","    r2 = r2_score(y_test_inv, preds_inv)\n","\n","    print(f\"RMSE: {rmse:.4f}\")\n","    print(f\"MAE: {mae:.4f}\")\n","    print(f\"R2: {r2:.4f}\")\n","\n","    # Vẽ đồ thị\n","    plt.plot(y_test_inv, label='True Price')\n","    plt.plot(preds_inv, label='Predicted Price')\n","    plt.title('Actual vs Predicted Stock Price')\n","    plt.xlabel('Timestep')\n","    plt.ylabel('Price')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","    return rmse, mae, r2\n","\n","\n","x_val_scaled = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=63, batch_size=BATCHSIZE).X_val_seq\n","y_val_scaled = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=63, batch_size=BATCHSIZE).y_val_seq\n","scaler_x = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=63, batch_size=BATCHSIZE).x_scaler\n","scaler_y = StockDataProcessor(data, 'FPT', lookback=WINDOWSIZE, forecast_horizon=63, batch_size=BATCHSIZE).y_scaler\n","\n","rmse, mae, r2 = evaluate_model(model_day63, x_val_scaled, y_val_scaled, scaler_x, scaler_y, FORECASTHORIZON)\n","print(rmse, mae, r2)"],"metadata":{"id":"ThwofKU9X7x9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#XGBoost"],"metadata":{"id":"HAilLx0ECImz"}},{"cell_type":"markdown","source":["##Preprocessed"],"metadata":{"id":"4K7LbY5Qb3F6"}},{"cell_type":"code","source":["import xgboost as xgb\n","class StockPreprocessor:\n","    def __init__(self, name, forecast_horizon):\n","        self.name = name\n","        self.forecast_horizon = forecast_horizon\n","        self.train_data = None\n","\n","    def _add_features(self, df: pd.DataFrame):\n","        df['target'] = (df[f'High_{self.name}'] + df[f'Low_{self.name}']) / 2\n","\n","        # Time features\n","        df['month_sin'] = np.sin(2 * np.pi * df.index.month / 12)\n","        df['month_cos'] = np.cos(2 * np.pi * df.index.month / 12)\n","        df['dow_sin'] = np.sin(2 * np.pi * df.index.dayofweek / 7)\n","        df['dow_cos'] = np.cos(2 * np.pi * df.index.dayofweek / 7)\n","        df['day_sin'] = np.sin(2 * np.pi * df.index.day / 31)\n","        df['day_cos'] = np.cos(2 * np.pi * df.index.day / 31)\n","        df['doy_sin'] = np.sin(2 * np.pi * df.index.dayofyear / 366)\n","        df['doy_cos'] = np.cos(2 * np.pi * df.index.dayofyear / 366)\n","\n","        # Lag Features\n","        lag_values = [1, 2, 3, 5, 7, 14, 21, 30, 63]\n","        for lag in lag_values:\n","            df[f'target_lag_{lag}'] = df['target'].shift(lag)\n","\n","        # Rolling Features\n","        window_sizes = [3, 7, 14, 21, 30, 63]\n","        for window in window_sizes:\n","            df[f'target_ma_{window}'] = df['target'].rolling(window=window, min_periods=1).mean()\n","            df[f'target_std_{window}'] = df['target'].rolling(window=window, min_periods=2).std()\n","            df[f'target_ema_{window}'] = df['target'].ewm(span=window, min_periods=1).mean()\n","\n","        # Price Change\n","        for period in [1, 3, 5, 7, 14, 21, 63]:\n","            df[f'price_change_{period}d'] = df['target'].diff(period)\n","            df[f'pct_change_{period}d'] = df['target'].pct_change(period) * 100\n","\n","        # Volatility\n","        df['pct_change_1d'] = df['target'].pct_change(1) * 100\n","        for window in [7, 14, 30, 60]:\n","            df[f'volatility_{window}d'] = df['pct_change_1d'].rolling(window=window, min_periods=2).std()\n","\n","        # RSI\n","        for window in [7, 14, 21, 63]:\n","            delta = df['target'].diff()\n","            gain = delta.where(delta > 0, 0.0)\n","            loss = -delta.where(delta < 0, 0.0)\n","            avg_gain = gain.ewm(com=window - 1, min_periods=window).mean()\n","            avg_loss = loss.ewm(com=window - 1, min_periods=window).mean()\n","            rs = avg_gain / avg_loss\n","            rs = rs.replace([np.inf, -np.inf], np.nan)\n","            df[f'rsi_{window}'] = 100 - (100 / (1 + rs))\n","\n","        # Price Range\n","        df['high_low_range'] = df[f'High_{self.name}'] - df[f'Low_{self.name}']\n","        df['high_low_range_pct'] = df['high_low_range'] / df['target'].replace(0, np.nan) * 100\n","\n","        df.drop(columns=['pct_change_1d'], inplace=True, errors='ignore')\n","        return df\n","\n","    def preprocess(self, data: pd.DataFrame) -> pd.DataFrame:\n","        df = data.copy()\n","        if 'Date' not in df.columns:\n","            raise ValueError(\"Data must contain 'Date' column.\")\n","        df['Date'] = pd.to_datetime(df['Date'])\n","        df = df.set_index('Date').sort_index()\n","        df = df.dropna(subset=[f'High_{self.name}', f'Low_{self.name}'])\n","        df = self._add_features(df)\n","\n","        # Tạo cột target tương lai (dự báo)\n","        df['future_target'] = df['target'].shift(-self.forecast_horizon)\n","\n","        df = df.dropna()\n","        return df\n","\n","    def split_data(self, df: pd.DataFrame, train_size=0.8, val_size=0.1):\n","        total_len = len(df)\n","        train_end = int(total_len * train_size)\n","        val_end = train_end + int(total_len * val_size)\n","\n","        X = df.drop(columns=['future_target'])\n","        y = df['future_target']\n","\n","        X_train, y_train = X.iloc[:train_end], y.iloc[:train_end]\n","        X_val, y_val = X.iloc[train_end:val_end], y.iloc[train_end:val_end]\n","        X_test, y_test = X.iloc[val_end:], y.iloc[val_end:]\n","\n","        self.train_data = X_train\n","        return X_train, y_train, X_val, y_val, X_test, y_test"],"metadata":{"id":"-IJSwaZKZvjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('FPT raw.csv')\n","preprocessor = StockPreprocessor(name='FPT', forecast_horizon=3)\n","processed_data = preprocessor.preprocess(data)\n","X_train_day3, y_train_day3, X_val_day3, y_val_day3, X_test_day3, y_test_day3 = preprocessor.split_data(processed_data)"],"metadata":{"id":"e4P393ReIINt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(y_test_day3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tm0SpdV9ITVS","executionInfo":{"status":"ok","timestamp":1746644602981,"user_tz":-420,"elapsed":12,"user":{"displayName":"Quang Tô","userId":"12736855403213190294"}},"outputId":"73dd5947-6bef-454b-a5d0-bde4111fe0c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Date\n","2024-07-09    133.175\n","2024-07-10    132.630\n","2024-07-11    132.480\n","2024-07-12    131.085\n","2024-07-15    128.705\n","               ...   \n","2025-03-28    121.550\n","2025-03-31    115.550\n","2025-04-01    109.750\n","2025-04-02    106.550\n","2025-04-03    102.900\n","Name: future_target, Length: 185, dtype: float64\n"]}]},{"cell_type":"markdown","source":["##XGBoost Day3"],"metadata":{"id":"RLLL-FGPb6uu"}},{"cell_type":"code","source":["data = pd.read_csv('FPT raw.csv')\n","preprocessor = StockPreprocessor(name='FPT', forecast_horizon=3)\n","processed_data = preprocessor.preprocess(data)\n","X_train_day3, y_train_day3, X_val_day3, y_val_day3, X_test_day3, y_test_day3 = preprocessor.split_data(processed_data)\n","\n","best_params_xgboost_day3 =  {'booster': 'gblinear', 'lambda': 0.07739166565294928, 'alpha': 4.6941386105684787e-07, 'colsample_bytree': 0.5262010137792733, 'subsample': 0.7941089864501972, 'learning_rate': 0.28037009442307836, 'n_estimators': 117, 'max_depth': 8, 'min_child_weight': 10, 'gamma': 2.021710932912922e-06}\n","model_xgboost_day3 = xgb.XGBRegressor(**best_params_xgboost_day3, objective='reg:squarederror')\n","model_xgboost_day3.fit(X_train_day3, y_train_day3)\n","\n","y_pred = model_xgboost_day3.predict(X_val_day3)\n","\n","# Evaluate the model\n","mae = mean_absolute_error(y_val_day3, y_pred)\n","r2 = r2_score(y_val_day3, y_pred)\n","rmse = np.sqrt(mean_squared_error(y_val_day3, y_pred))\n","\n","print(f\"MAE: {mae}\")\n","print(f\"R-squared: {r2}\")\n","print(f\"RMSE: {rmse}\")\n","\n","# Plot actual vs predicted values\n","plt.figure(figsize=(10, 6))\n","plt.plot(y_val_day3.index, y_val_day3.values, label='Actual')\n","plt.plot(y_val_day3.index, y_pred, label='Predicted')\n","plt.xlabel('Date')\n","plt.ylabel('Close Price')\n","plt.title('Actual vs Predicted Close Prices')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"ATDsRK9Rb-i3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##XGBoost Day 7"],"metadata":{"id":"Lm65g1JnitJ9"}},{"cell_type":"code","source":["data = pd.read_csv('FPT raw.csv')\n","preprocessor = StockPreprocessor(name='FPT', forecast_horizon=7)\n","processed_data = preprocessor.preprocess(data)\n","X_train_day7, y_train_day7, X_val_day7, y_val_day7, X_test_day7, y_test_day7 = preprocessor.split_data(processed_data)\n","\n","best_params_xgboost_day7 = {'booster': 'gblinear', 'lambda': 0.08428016250851712, 'alpha': 0.011146562831606347, 'colsample_bytree': 0.710628701179182, 'subsample': 0.6157249107063909, 'learning_rate': 0.2990197318372416, 'n_estimators': 503, 'max_depth': 9, 'min_child_weight': 4, 'gamma': 0.00015002114702489098}\n","model_xgboost_day7 = xgb.XGBRegressor(**best_params_xgboost_day7, objective='reg:squarederror')\n","model_xgboost_day7.fit(X_train_day7, y_train_day7)\n","\n","y_pred = model_xgboost_day7.predict(X_val_day7)\n","\n","# Evaluate the model\n","mae = mean_absolute_error(y_val_day7, y_pred)\n","r2 = r2_score(y_val_day7, y_pred)\n","rmse = np.sqrt(mean_squared_error(y_val_day7, y_pred))\n","\n","print(f\"MAE: {mae}\")\n","print(f\"R-squared: {r2}\")\n","print(f\"RMSE: {rmse}\")\n","\n","# Plot actual vs predicted values\n","plt.figure(figsize=(10, 6))\n","plt.plot(y_val_day7.index, y_val_day7.values, label='Actual')\n","plt.plot(y_val_day7.index, y_pred, label='Predicted')\n","plt.xlabel('Date')\n","plt.ylabel('Close Price')\n","plt.title('Actual vs Predicted Close Prices')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"79_hNYGMiOZf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##XGBoost Day 21"],"metadata":{"id":"LCAX6UyWiyhX"}},{"cell_type":"code","source":["data = pd.read_csv('FPT raw.csv')\n","preprocessor = StockPreprocessor(name='FPT', forecast_horizon=21)\n","processed_data = preprocessor.preprocess(data)\n","X_train_day21, y_train_day21, X_val_day21, y_val_day21, X_test_day21, y_test_day21 = preprocessor.split_data(processed_data)\n","\n","best_params_day21 = {'booster': 'gblinear', 'lambda': 0.815370923350939, 'alpha': 0.21153871972945865, 'colsample_bytree': 0.7375542070813348, 'subsample': 0.737204775621541, 'learning_rate': 0.010255357448348582, 'n_estimators': 950, 'max_depth': 6, 'min_child_weight': 8, 'gamma': 0.022337610033267303}\n","model_xgboost_day21 = xgb.XGBRegressor(**best_params_day21, objective='reg:squarederror')\n","model_xgboost_day21.fit(X_train_day21, y_train_day21)\n","\n","y_pred = model_xgboost_day21.predict(X_val_day21)\n","\n","# Evaluate the model\n","mae = mean_absolute_error(y_val_day21, y_pred)\n","r2 = r2_score(y_val_day21, y_pred)\n","rmse = np.sqrt(mean_squared_error(y_val_day21, y_pred))\n","\n","print(f\"MAE: {mae}\")\n","print(f\"R-squared: {r2}\")\n","print(f\"RMSE: {rmse}\")\n","\n","# Plot actual vs predicted values\n","plt.figure(figsize=(10, 6))\n","plt.plot(y_val_day21.index, y_val_day21.values, label='Actual')\n","plt.plot(y_val_day21.index, y_pred, label='Predicted')\n","plt.xlabel('Date')\n","plt.ylabel('Close Price')\n","plt.title('Actual vs Predicted Close Prices')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"oQoF7_xJi03f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##XGBoost Day 63"],"metadata":{"id":"tjC3WjZcj-cS"}},{"cell_type":"code","source":["data = pd.read_csv('FPT raw.csv')\n","preprocessor = StockPreprocessor(name='FPT', forecast_horizon=63)\n","processed_data = preprocessor.preprocess(data)\n","X_train_day63, y_train_day63, X_val_day63, y_val_day63, X_test_day63, y_test_day63 = preprocessor.split_data(processed_data)\n","\n","best_params_xgboost_day63 = {'booster': 'gblinear', 'lambda': 0.004271167573513258, 'alpha': 1.0297674578199017e-07, 'colsample_bytree': 0.31069926016540655, 'subsample': 0.5178924177280366, 'learning_rate': 0.2993833956727135, 'n_estimators': 818, 'max_depth': 9, 'min_child_weight': 8, 'gamma': 0.0035924978449316464}\n","\n","\n","model_xgboost_day63 = xgb.XGBRegressor(**best_params_day63, objective='reg:squarederror')\n","model_xgboost_day63.fit(X_train_day63, y_train_day63)\n","\n","y_pred = model_xgboost_day63.predict(X_val_day63)\n","\n","# Evaluate the model\n","mae = mean_absolute_error(y_val_day63, y_pred)\n","r2 = r2_score(y_val_day63, y_pred)\n","rmse = np.sqrt(mean_squared_error(y_val_day63, y_pred))\n","\n","print(f\"MAE: {mae}\")\n","print(f\"R-squared: {r2}\")\n","print(f\"RMSE: {rmse}\")\n","\n","# Plot actual vs predicted values\n","plt.figure(figsize=(10, 6))\n","plt.plot(y_val_day63.index, y_val_day63.values, label='Actual')\n","plt.plot(y_val_day63.index, y_pred, label='Predicted')\n","plt.xlabel('Date')\n","plt.ylabel('Close Price')\n","plt.title('Actual vs Predicted Close Prices')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"Cet21Rffj_3c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Finetune"],"metadata":{"id":"BquWpDdr-Zo5"}},{"cell_type":"markdown","source":["## Day 3"],"metadata":{"id":"qoPIXnGe_Cb3"}},{"cell_type":"code","source":["\n","import numpy as np\n","def predict_next_days(model, data_loader, scaler_y, num_days=3, device=None):\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model.eval()\n","    model.to(device)\n","    predictions = []\n","    with torch.no_grad():\n","        for X, _ in data_loader:\n","            X = X.to(device)\n","            pred = model(X).cpu().numpy()\n","            predictions.extend(pred)\n","    predictions = scaler_y.inverse_transform(np.array(predictions).reshape(-1, 1))\n","    return predictions[-num_days:]\n","\n","next_3_days_predictions = predict_next_days(model_day3, test_loader_day3, scaler_y_day3, num_days=3)\n","print(\"Predictions for the next 3 days:\", next_3_days_predictions)\n","\n","predicted_df_day3 = pd.DataFrame({'Predicted Price': next_3_days_predictions.flatten()})\n","actual_prices_day3 = data['Close_CMC'][-len(next_3_days_predictions):].values\n","actual_df_day3 = pd.DataFrame({'Actual Price': actual_prices_day3})\n","\n","predicted_df_day3.to_csv('predicted_prices_day3.csv', index=False)\n","actual_df_day3.to_csv('actual_prices_day3.csv', index=False)\n","\n","predicted_prices_day3 = pd.read_csv('predicted_prices_day3.csv')['Predicted Price'].values\n","actual_prices_day3 = pd.read_csv('actual_prices_day3.csv')['Actual Price'].values\n","\n","df_actual_day3 = pd.DataFrame({'Actual Price': actual_prices_day3})\n","result_df_actual_day3 = df_actual_day3.apply(lambda x: np.log(x) - np.log(x.shift(3))).iloc[3:]\n","\n","df_predicted_day3 = pd.DataFrame({'Predicted Price': predicted_prices_day3})\n","result_df_predicted_day3 = df_predicted_day3.apply(lambda x: np.log(x) - np.log(x.shift(3))).iloc[3:]\n","\n","print(\"Result for Actual Prices (Day 3):\\n\", result_df_actual_day3)\n","print(\"\\nResult for Predicted Prices (Day 3):\\n\", result_df_predicted_day3)\n","\n","predicted_prices_day3 = pd.read_csv('predicted_prices_day3.csv')['Predicted Price'].values\n","actual_prices_day3 = pd.read_csv('actual_prices_day3.csv')['Actual Price'].values\n","\n","portfolio_actual_return_day3 = (actual_prices_day3[-1] - actual_prices_day3[0]) / actual_prices_day3[0]\n","\n","daily_returns_day3 = np.diff(actual_prices_day3) / actual_prices_day3[:-1]\n","sharpe_ratio_day3 = np.mean(daily_returns_day3) / np.std(daily_returns_day3) if np.std(daily_returns_day3) != 0 else 0\n","\n","actual_variance_day3 = np.var(daily_returns_day3)\n","\n","predicted_returns_day3 = (predicted_prices_day3[-1] - predicted_prices_day3[0]) / predicted_prices_day3[0]\n","\n","print(f\"Day 3 - Portfolio Actual Return: {portfolio_actual_return_day3:.4f}\")\n","print(f\"Day 3 - Sharpe Ratio: {sharpe_ratio_day3:.4f}\")\n","print(f\"Day 3 - Actual Variance: {actual_variance_day3:.4f}\")\n","print(f\"Day 3 - Predicted Returns: {predicted_returns_day3:.4f}\")"],"metadata":{"id":"LPp9B8aK_Dbj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Day 7"],"metadata":{"id":"zthz96xn_Ej5"}},{"cell_type":"code","source":["\n","import numpy as np\n","def predict_next_days(model, data_loader, scaler_y, num_days=7, device=None):\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model.eval()\n","    model.to(device)\n","    predictions = []\n","    with torch.no_grad():\n","        for X, _ in data_loader:\n","            X = X.to(device)\n","            pred = model(X).cpu().numpy()\n","            predictions.extend(pred)\n","    predictions = scaler_y.inverse_transform(np.array(predictions).reshape(-1, 1))\n","    return predictions[-num_days:]\n","\n","next_7_days_predictions = predict_next_days(model_day7, test_loader_day7, scaler_y_day7, num_days=7)\n","print(\"Predictions for the next 7 days:\", next_7_days_predictions)\n","\n","predicted_df_day7 = pd.DataFrame({'Predicted Price': next_7_days_predictions.flatten()})\n","actual_prices_day7 = data['Close_CMC'][-len(next_7_days_predictions):].values\n","actual_df_day7 = pd.DataFrame({'Actual Price': actual_prices_day7})\n","\n","predicted_df_day7.to_csv('predicted_prices_day7.csv', index=False)\n","actual_df_day7.to_csv('actual_prices_day7.csv', index=False)\n","\n","predicted_prices_day7 = pd.read_csv('predicted_prices_day7.csv')['Predicted Price'].values\n","actual_prices_day7 = pd.read_csv('actual_prices_day7.csv')['Actual Price'].values\n","\n","df_actual_day7 = pd.DataFrame({'Actual Price': actual_prices_day7})\n","result_df_actual_day7 = df_actual_day7.apply(lambda x: np.log(x) - np.log(x.shift(7))).iloc[7:]\n","\n","df_predicted_day7 = pd.DataFrame({'Predicted Price': predicted_prices_day7})\n","result_df_predicted_day7 = df_predicted_day7.apply(lambda x: np.log(x) - np.log(x.shift(7))).iloc[7:]\n","\n","print(\"Result for Actual Prices (Day 7):\\n\", result_df_actual_day7)\n","print(\"\\nResult for Predicted Prices (Day 7):\\n\", result_df_predicted_day7)\n","\n","predicted_prices_day7 = pd.read_csv('predicted_prices_day7.csv')['Predicted Price'].values\n","actual_prices_day7 = pd.read_csv('actual_prices_day7.csv')['Actual Price'].values\n","\n","portfolio_actual_return_day7 = (actual_prices_day7[-1] - actual_prices_day7[0]) / actual_prices_day7[0]\n","\n","daily_returns_day7 = np.diff(actual_prices_day7) / actual_prices_day7[:-1]\n","sharpe_ratio_day7 = np.mean(daily_returns_day7) / np.std(daily_returns_day7) if np.std(daily_returns_day7) != 0 else 0\n","\n","actual_variance_day7 = np.var(daily_returns_day7)\n","\n","predicted_returns_day7 = (predicted_prices_day7[-1] - predicted_prices_day7[0]) / predicted_prices_day7[0]\n","\n","print(f\"Day 7 - Portfolio Actual Return: {portfolio_actual_return_day7:.4f}\")\n","print(f\"Day 7 - Sharpe Ratio: {sharpe_ratio_day7:.4f}\")\n","print(f\"Day 7 - Actual Variance: {actual_variance_day7:.4f}\")\n","print(f\"Day 7 - Predicted Returns: {predicted_returns_day7:.4f}\")"],"metadata":{"id":"DZPglkme_F0j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Day 21"],"metadata":{"id":"E4KYQWlW_KF_"}},{"cell_type":"code","source":["\n","import numpy as np\n","def predict_next_days(model, data_loader, scaler_y, num_days=21, device=None):\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model.eval()\n","    model.to(device)\n","    predictions = []\n","    with torch.no_grad():\n","        for X, _ in data_loader:\n","            X = X.to(device)\n","            pred = model(X).cpu().numpy()\n","            predictions.extend(pred)\n","    predictions = scaler_y.inverse_transform(np.array(predictions).reshape(-1, 1))\n","    return predictions[-num_days:]\n","\n","next_21_days_predictions = predict_next_days(model_day21, test_loader_day21, scaler_y_day21, num_days=21)\n","print(\"Predictions for the next 21 days:\", next_21_days_predictions)\n","\n","predicted_df_day21 = pd.DataFrame({'Predicted Price': next_21_days_predictions.flatten()})\n","actual_prices_day21 = data['Close_CMC'][-len(next_21_days_predictions):].values\n","actual_df_day21 = pd.DataFrame({'Actual Price': actual_prices_day21})\n","\n","predicted_df_day21.to_csv('predicted_prices_day21.csv', index=False)\n","actual_df_day21.to_csv('actual_prices_day21.csv', index=False)\n","\n","predicted_prices_day21 = pd.read_csv('predicted_prices_day21.csv')['Predicted Price'].values\n","actual_prices_day21 = pd.read_csv('actual_prices_day21.csv')['Actual Price'].values\n","\n","df_actual_day21 = pd.DataFrame({'Actual Price': actual_prices_day21})\n","result_df_actual_day21 = df_actual_day21.apply(lambda x: np.log(x) - np.log(x.shift(21))).iloc[21:]\n","\n","df_predicted_day21 = pd.DataFrame({'Predicted Price': predicted_prices_day21})\n","result_df_predicted_day21 = df_predicted_day21.apply(lambda x: np.log(x) - np.log(x.shift(21))).iloc[21:]\n","\n","print(\"Result for Actual Prices (Day 21):\\n\", result_df_actual_day21)\n","print(\"\\nResult for Predicted Prices (Day 21):\\n\", result_df_predicted_day21)\n","\n","predicted_prices_day21 = pd.read_csv('predicted_prices_day21.csv')['Predicted Price'].values\n","actual_prices_day21 = pd.read_csv('actual_prices_day21.csv')['Actual Price'].values\n","\n","portfolio_actual_return_day21 = (actual_prices_day21[-1] - actual_prices_day21[0]) / actual_prices_day21[0]\n","\n","daily_returns_day21 = np.diff(actual_prices_day21) / actual_prices_day21[:-1]\n","sharpe_ratio_day21 = np.mean(daily_returns_day21) / np.std(daily_returns_day21) if np.std(daily_returns_day21) != 0 else 0\n","\n","actual_variance_day21 = np.var(daily_returns_day21)\n","\n","predicted_returns_day21 = (predicted_prices_day21[-1] - predicted_prices_day21[0]) / predicted_prices_day21[0]\n","\n","print(f\"Day 21 - Portfolio Actual Return: {portfolio_actual_return_day21:.4f}\")\n","print(f\"Day 21 - Sharpe Ratio: {sharpe_ratio_day21:.4f}\")\n","print(f\"Day 21 - Actual Variance: {actual_variance_day21:.4f}\")\n","print(f\"Day 21 - Predicted Returns: {predicted_returns_day21:.4f}\")"],"metadata":{"id":"st3PXzD4_LIL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Day 63"],"metadata":{"id":"it7c4HFv-xhA"}},{"cell_type":"code","source":["\n","import numpy as np\n","def predict_next_days(model, data_loader, scaler_y, num_days=63, device=None):\n","    if device is None:\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model.eval()\n","    model.to(device)\n","    predictions = []\n","    with torch.no_grad():\n","        for X, _ in data_loader:\n","            X = X.to(device)\n","            pred = model(X).cpu().numpy()\n","            predictions.extend(pred)\n","    predictions = scaler_y.inverse_transform(np.array(predictions).reshape(-1, 1))\n","    return predictions[-num_days:]\n","\n","next_63_days_predictions = predict_next_days(model_day63, test_loader_day63, scaler_y_day63, num_days=63)\n","print(\"Predictions for the next 63 days:\", next_63_days_predictions)\n","\n","predicted_df_day63 = pd.DataFrame({'Predicted Price': next_63_days_predictions.flatten()})\n","actual_prices_day63 = data['Close_CMC'][-len(next_63_days_predictions):].values\n","actual_df_day63 = pd.DataFrame({'Actual Price': actual_prices_day63})\n","\n","predicted_df_day63.to_csv('predicted_prices_day63.csv', index=False)\n","actual_df_day63.to_csv('actual_prices_day63.csv', index=False)\n","\n","predicted_prices_day63 = pd.read_csv('predicted_prices_day63.csv')['Predicted Price'].values\n","actual_prices_day63 = pd.read_csv('actual_prices_day63.csv')['Actual Price'].values\n","\n","df_actual_day63 = pd.DataFrame({'Actual Price': actual_prices_day63})\n","result_df_actual_day63 = df_actual_day63.apply(lambda x: np.log(x) - np.log(x.shift(63))).iloc[63:]\n","\n","df_predicted_day63 = pd.DataFrame({'Predicted Price': predicted_prices_day63})\n","result_df_predicted_day63 = df_predicted_day63.apply(lambda x: np.log(x) - np.log(x.shift(63))).iloc[63:]\n","\n","print(\"Result for Actual Prices (Day 63):\\n\", result_df_actual_day63)\n","print(\"\\nResult for Predicted Prices (Day 63):\\n\", result_df_predicted_day63)\n","\n","predicted_prices_day63 = pd.read_csv('predicted_prices_day63.csv')['Predicted Price'].values\n","actual_prices_day63 = pd.read_csv('actual_prices_day63.csv')['Actual Price'].values\n","\n","portfolio_actual_return_day63 = (actual_prices_day63[-1] - actual_prices_day63[0]) / actual_prices_day63[0]\n","\n","daily_returns_day63 = np.diff(actual_prices_day63) / actual_prices_day63[:-1]\n","sharpe_ratio_day63 = np.mean(daily_returns_day63) / np.std(daily_returns_day63) if np.std(daily_returns_day63) != 0 else 0\n","\n","actual_variance_day63 = np.var(daily_returns_day63)\n","\n","predicted_returns_day63 = (predicted_prices_day63[-1] - predicted_prices_day63[0]) / predicted_prices_day63[0]\n","\n","print(f\"Day 63 - Portfolio Actual Return: {portfolio_actual_return_day63:.4f}\")\n","print(f\"Day 63 - Sharpe Ratio: {sharpe_ratio_day63:.4f}\")\n","print(f\"Day 63 - Actual Variance: {actual_variance_day63:.4f}\")\n","print(f\"Day 63 - Predicted Returns: {predicted_returns_day63:.4f}\")"],"metadata":{"id":"BAZoaRVl-cao"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1746870428091}],"collapsed_sections":["mD_6gT1y0aIY","GnqVDs4qVOzB","7rZcxfhOZHAA","fBgLtNg8vOgG","HAilLx0ECImz","4K7LbY5Qb3F6","BquWpDdr-Zo5","zthz96xn_Ej5"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}